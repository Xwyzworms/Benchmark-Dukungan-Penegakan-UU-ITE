{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Gemastik14Merged.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f4e583fb63741e6bd86e21a6a770513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9b2ab22d7ed94a5ca36f3e44347bcaa2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f12c01f1496941919dc8fcbd438b2019",
              "IPY_MODEL_8181c076d9b54bdb99e787ef5bfad760"
            ]
          }
        },
        "9b2ab22d7ed94a5ca36f3e44347bcaa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f12c01f1496941919dc8fcbd438b2019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2f2a3d25dfd44390890e30e687a87673",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1534,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1534,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57e4f3547d4d422bb87f88b4f80595e8"
          }
        },
        "8181c076d9b54bdb99e787ef5bfad760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0bfa4206796344eca438fc3398f55141",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.53k/1.53k [00:15&lt;00:00, 99.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b451434baaf14dc093c92d8f8abc6bae"
          }
        },
        "2f2a3d25dfd44390890e30e687a87673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57e4f3547d4d422bb87f88b4f80595e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bfa4206796344eca438fc3398f55141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b451434baaf14dc093c92d8f8abc6bae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f56dcda3ac7440a887b3a1c1ac1b2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c071e6736d6472aa4276ad183054a45",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0db91c7c3b2e428ea0f8359bf640d8ab",
              "IPY_MODEL_b28e4b34521d483aacb96b142fbc7c27"
            ]
          }
        },
        "2c071e6736d6472aa4276ad183054a45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0db91c7c3b2e428ea0f8359bf640d8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_244e91680b4e48ee97f1f61443f5b3d3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 655812184,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 655812184,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f754979bf6b140678dab592efb733fad"
          }
        },
        "b28e4b34521d483aacb96b142fbc7c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08ad2db7d3f74d568969c303ebe310ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 656M/656M [00:15&lt;00:00, 42.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d23428b37e784af2865370d0681bdd1c"
          }
        },
        "244e91680b4e48ee97f1f61443f5b3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f754979bf6b140678dab592efb733fad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08ad2db7d3f74d568969c303ebe310ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d23428b37e784af2865370d0681bdd1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8ecabce6c5e4dc48fecf6e2e9d16381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_54710d233e004a818092f2c833d85270",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1906ebe7e70e4052a4af42395a7269ba",
              "IPY_MODEL_a746499e302041b3bc8bebddeabb18e5"
            ]
          }
        },
        "54710d233e004a818092f2c833d85270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1906ebe7e70e4052a4af42395a7269ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7714a4e4d5284dbfaecdd456d8f72885",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2df1a17306c5460fb256723291e1190c"
          }
        },
        "a746499e302041b3bc8bebddeabb18e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9cd5ab3622404253a3b50f877d427fed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 6.70kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea0e4eca556c4a9199069739f42d4245"
          }
        },
        "7714a4e4d5284dbfaecdd456d8f72885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2df1a17306c5460fb256723291e1190c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cd5ab3622404253a3b50f877d427fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea0e4eca556c4a9199069739f42d4245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72284e9ed1cb4d5c868af3cb28b7a96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_38962294dfe245c2acd5cabfa3b67b37",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bcabce0f6f0d40bea9d3f47a81915193",
              "IPY_MODEL_d6bceda25c414883baa6de6518de7e49"
            ]
          }
        },
        "38962294dfe245c2acd5cabfa3b67b37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcabce0f6f0d40bea9d3f47a81915193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af48306e91c44c919092449425c3d92f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 668101576,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 668101576,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8d42c0869524761af92aab581a56165"
          }
        },
        "d6bceda25c414883baa6de6518de7e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99b67f2a5a0641efae500aac57baddf8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 668M/668M [00:18&lt;00:00, 36.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5b86f04ec7c45d6b9ae25f23f921134"
          }
        },
        "af48306e91c44c919092449425c3d92f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8d42c0869524761af92aab581a56165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99b67f2a5a0641efae500aac57baddf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5b86f04ec7c45d6b9ae25f23f921134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "946da461b84241468697c518667b2759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d2c278ff1ed741ffa27607f4bffcab97",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2f182570eda547f986e52924933053e8",
              "IPY_MODEL_c94abdc96a714131af2785ece5e3a0fc"
            ]
          }
        },
        "d2c278ff1ed741ffa27607f4bffcab97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f182570eda547f986e52924933053e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4bf16fb47cd84ec68cbad4e2f7e0401b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 468,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 468,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03d72253449f4630bdc1aca9ba5b9a39"
          }
        },
        "c94abdc96a714131af2785ece5e3a0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e6c31ef3d48d43cba07f9438a9da4a61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 468/468 [00:15&lt;00:00, 31.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58fe91c6a7884a86aead86800b3169c4"
          }
        },
        "4bf16fb47cd84ec68cbad4e2f7e0401b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03d72253449f4630bdc1aca9ba5b9a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6c31ef3d48d43cba07f9438a9da4a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58fe91c6a7884a86aead86800b3169c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c605ded2f9934524aa450d211c3906ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b8d4432c6aea42f99d21326b4e57b04b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ffef895755924ed0851aaab96beec4e5",
              "IPY_MODEL_afb274e08cb6471886da11b89ab659a1"
            ]
          }
        },
        "b8d4432c6aea42f99d21326b4e57b04b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffef895755924ed0851aaab96beec4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fbcda1620e924ea8b7f1cebd14f5ec79",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 545136632,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 545136632,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_044d70c68bc1452c8fde0743735d26af"
          }
        },
        "afb274e08cb6471886da11b89ab659a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d43dd761c2b4d559a1dbc325e59370c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 545M/545M [00:14&lt;00:00, 36.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a901f80a9ea4bdc9906360ebc08f630"
          }
        },
        "fbcda1620e924ea8b7f1cebd14f5ec79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "044d70c68bc1452c8fde0743735d26af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d43dd761c2b4d559a1dbc325e59370c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a901f80a9ea4bdc9906360ebc08f630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "899dbdfa0abf4c7ea2d2d535feffdd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78e68979629d47ac89a85e2acb45181b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_900a0714c6194c299003c34022d6bba6",
              "IPY_MODEL_d82ef5ed0d6e41b6a8a929a9bfc44883"
            ]
          }
        },
        "78e68979629d47ac89a85e2acb45181b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "900a0714c6194c299003c34022d6bba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6213930b9a5e4acc8142687e6688e1be",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_744df59738a445ce814caf40570f4d5d"
          }
        },
        "d82ef5ed0d6e41b6a8a929a9bfc44883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e60c74eb0e624ae0bf681e40833e4256",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:41&lt;00:00, 12.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d40c0111e83842c9a3382b1657a4df6b"
          }
        },
        "6213930b9a5e4acc8142687e6688e1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "744df59738a445ce814caf40570f4d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e60c74eb0e624ae0bf681e40833e4256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d40c0111e83842c9a3382b1657a4df6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d20b7bba73a4003aa2b1484b1c969b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8aa733c51efb45ff87c0ae72e32199fc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_554ecafdc260418698a8b26ffa9b3d26",
              "IPY_MODEL_c214f43252b649df8bd4591dea496c97"
            ]
          }
        },
        "8aa733c51efb45ff87c0ae72e32199fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "554ecafdc260418698a8b26ffa9b3d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_31172506414f447eac34d89ff608d504",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1885418496,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1885418496,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec2325ffefd440f9a222846e163a25ea"
          }
        },
        "c214f43252b649df8bd4591dea496c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a10f6c1e6469459482b77fe43f2c5e27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.89G/1.89G [00:41&lt;00:00, 45.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d17aa873854f4bf8ae23821c4de04372"
          }
        },
        "31172506414f447eac34d89ff608d504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec2325ffefd440f9a222846e163a25ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a10f6c1e6469459482b77fe43f2c5e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d17aa873854f4bf8ae23821c4de04372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e57e10f8039455d8fa0821d4e9ea538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ad5ebdc8f434d0b93e8de318ead4384",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b0995a0ccb84cc69287c0902e23c445",
              "IPY_MODEL_6d1798b156044dda800d51bcfdc24b4f"
            ]
          }
        },
        "5ad5ebdc8f434d0b93e8de318ead4384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b0995a0ccb84cc69287c0902e23c445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_07fde35a6c654a6d8197b77da74f8179",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 573,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 573,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_199728cf370b423b81a30a183da89636"
          }
        },
        "6d1798b156044dda800d51bcfdc24b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc2145f1ca524564a16e00a8ad09c2ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 573/573 [00:00&lt;00:00, 1.21kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08ccfd49b99b4e54810ff17eb0c002a9"
          }
        },
        "07fde35a6c654a6d8197b77da74f8179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "199728cf370b423b81a30a183da89636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc2145f1ca524564a16e00a8ad09c2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08ccfd49b99b4e54810ff17eb0c002a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32e4044e736449c18664e71d2af37891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8fd3e33e6fef4e4587779fc45c61f0fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3c3474c6353e4c18ad30548e742466fb",
              "IPY_MODEL_6ed1605ec9a54b0cb9e739e0f0fba113"
            ]
          }
        },
        "8fd3e33e6fef4e4587779fc45c61f0fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c3474c6353e4c18ad30548e742466fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d90d6f832ba844cba4e16e44ae18fbc0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 497933648,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 497933648,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e98e5e1fe631412a819905b76b709cfc"
          }
        },
        "6ed1605ec9a54b0cb9e739e0f0fba113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_629e01d828464d2cb9df5adefcfa2d62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 498M/498M [00:12&lt;00:00, 40.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa8bf4b57ccf4422bdfa8c0f24531c15"
          }
        },
        "d90d6f832ba844cba4e16e44ae18fbc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e98e5e1fe631412a819905b76b709cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "629e01d828464d2cb9df5adefcfa2d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa8bf4b57ccf4422bdfa8c0f24531c15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQYl7NXPFIxx"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1cuJsP-X7pOdvQGRxOBESp9N9HSiSUemQ?usp=sharing\">\n",
        "  <img align=\"center\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1C8IZ2UF_CK",
        "outputId": "1efe837d-b950-4d29-b50c-bd1cd43f1a63"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "#!pip install tensorflow==2.4.0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.6 MB 8.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 67.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3 MB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 636 kB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 8.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lwpkMP9FIST",
        "outputId": "582d9df2-42d7-4eed-8c0a-e38540574cef"
      },
      "source": [
        "# import module\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "MAX_LENGTHS = 50\n",
        "\n",
        "NUM_CATEGORICAL = 3\n",
        "dfResult = pd.DataFrame(columns=[ \"rataAccTrain\", \"rataAccVal\",\n",
        "                    \"rataLossTrain\", \"rataLossVal\",\n",
        "                    \"precisionTrain\",\"precisionVal\",\n",
        "                    \"recallTrain\",\"recallVal\",\"ModelName\"])\n",
        "HISTORY_TRANSFORMERS = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOBnasnPHS0o"
      },
      "source": [
        "IMPORTING ALL DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Kn8T4ZnHQVk",
        "outputId": "6ed63d47-54d5-4679-a217-a99f34eeb2c7"
      },
      "source": [
        "!gdown --id 1dhdMKM9akp0krL9ObL-kn8K9gSVOwPUp\n",
        "!gdown --id 1160UzrabHFjB4QjLs6IWU4mZ6fZroGNf\n",
        "!gdown --id 10FbqBhDzGl_JsFLxFI8SvWmouc0FWQtd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dhdMKM9akp0krL9ObL-kn8K9gSVOwPUp\n",
            "To: /content/AllData.csv\n",
            "3.25MB [00:00, 102MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1160UzrabHFjB4QjLs6IWU4mZ6fZroGNf\n",
            "To: /content/All Data Undersampling Max 200.csv\n",
            "100% 895k/895k [00:00<00:00, 59.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10FbqBhDzGl_JsFLxFI8SvWmouc0FWQtd\n",
            "To: /content/Normal.csv\n",
            "100% 443k/443k [00:00<00:00, 60.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "712XA0MkKq0j"
      },
      "source": [
        "## Yow Read the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HrdEgPocP5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c835f8-ccf1-41d8-d30a-3ce34af4fb49"
      },
      "source": [
        "!pip install openpyxl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (2.5.9)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.4.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ_LbpbkFyYN"
      },
      "source": [
        "dfAllData = pd.read_csv(\"All Data Undersampling Max 200.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_CHxM8UIdHr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bcda1641-d072-4db2-f3f0-850077b4acc9"
      },
      "source": [
        "sample = dfAllData.loc[1,\"tweet\"]\n",
        "def cleanIt(text):\n",
        "  \n",
        "  text = str(text)\n",
        "  text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[#]+|[^A-Za-z0-9]+\"\n",
        "  text_cleaning_hash = \"#[A-Za-z0-9]+\" \n",
        "\n",
        "  text = re.sub(text_cleaning_hash, \" \",text).rstrip()\n",
        "  text = re.sub(text_cleaning_re, \" \",text).rstrip()\n",
        "  \n",
        "  return text\n",
        "cleanIt(sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'status dukung gerakan matikan lilin untuk ahok gubernur sebut akun facebok dihack'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDt9bfTBLtEN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f65d21d-690c-4e3b-f9c8-e4c4c6b40b1d"
      },
      "source": [
        "stopword = nltk.corpus.stopwords.words('indonesian')\n",
        "def stopWord(text):\n",
        "  text = text.split()\n",
        "  return \" \".join([t for t in text if t not in stopword])\n",
        "stopWord(\"bilamana apabila saya  \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bilamana'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAbalBpo-xSx"
      },
      "source": [
        "dfNormal = pd.read_csv(\"Normal.csv\")\n",
        "dfAllData = dfAllData[dfAllData[\"labels\"] != 0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vroVpYrlQM6"
      },
      "source": [
        "dfAllData.loc[dfAllData[\"labels\"] == 3,\"labels\"]= 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOs7NNTfAPkG"
      },
      "source": [
        "dfNormal.loc[:,\"labels\"] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pCvgBqA_YTY"
      },
      "source": [
        "dfAllData = pd.concat([dfAllData,dfNormal])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM6_2ULFJlC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "c84adb02-a217-4d0e-99aa-1425ff58d9f3"
      },
      "source": [
        "dfAllData[\"tweet\"] = dfAllData[\"tweet\"].apply(cleanIt)\n",
        "dfAllData[\"tweet\"] = dfAllData[\"tweet\"].apply(stopWord)\n",
        "dfAllData = dfAllData[dfAllData[\"tweet\"].apply(lambda x : len(x.rstrip().split()) > 4) == True ]\n",
        "dfAllData[dfAllData[\"tweet\"].apply(lambda x : len(x.split()) < 4) == True]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [tweet, labels]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXSIGpHtCb0O"
      },
      "source": [
        "for i in range(5):\n",
        "    dfAllData = dfAllData.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "LuJh0YwkfJuI",
        "outputId": "c5873da6-eb8f-45e0-ef9f-4a9921ac3a99"
      },
      "source": [
        "dfAllData"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>videos of italian suicide who lost entire fami...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tahapan pelaksanan skb cpns penentuan peserta ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>anies sandi dikenang sejarah menang terhormat ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>resto dijadikan salah pilihan makan dipusat ko...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>isu bohong kali kepala divisi hubungan masyara...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6380</th>\n",
              "      <td>benaran ikan duyung benaran sesuai gambaran ca...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6381</th>\n",
              "      <td>bank mandiri kartu kredit senilai rp orang cep...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6382</th>\n",
              "      <td>pb dunia kumpulkan dana kemanusian rp triliun ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6383</th>\n",
              "      <td>disinformasi diedarkan sabu kristal pipapipa b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6384</th>\n",
              "      <td>jokowi pengecut mundur jabatan presiden</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6385 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweet  labels\n",
              "0     videos of italian suicide who lost entire fami...       1\n",
              "1     tahapan pelaksanan skb cpns penentuan peserta ...       1\n",
              "2     anies sandi dikenang sejarah menang terhormat ...       2\n",
              "3     resto dijadikan salah pilihan makan dipusat ko...       0\n",
              "4     isu bohong kali kepala divisi hubungan masyara...       1\n",
              "...                                                 ...     ...\n",
              "6380  benaran ikan duyung benaran sesuai gambaran ca...       1\n",
              "6381  bank mandiri kartu kredit senilai rp orang cep...       1\n",
              "6382  pb dunia kumpulkan dana kemanusian rp triliun ...       2\n",
              "6383  disinformasi diedarkan sabu kristal pipapipa b...       1\n",
              "6384            jokowi pengecut mundur jabatan presiden       2\n",
              "\n",
              "[6385 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-UjjUUQAg-t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "95c30e17-5bd7-45fa-cc28-75813469b84c"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "counted = dfAllData.groupby('labels')[\"labels\"].aggregate(\"count\")\n",
        "print(counted)\n",
        "fig = go.Figure()\n",
        "fig.add_traces(go.Bar(y = [\"Normal\",\"Berita Bohong\",\"HateSpeech\",\"Offensive\"],x = counted,orientation=\"h\"))\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels\n",
            "0    1759\n",
            "1    1657\n",
            "2    2969\n",
            "Name: labels, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"d22a558c-0542-4d4a-9d71-cce04353adc1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"d22a558c-0542-4d4a-9d71-cce04353adc1\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'd22a558c-0542-4d4a-9d71-cce04353adc1',\n",
              "                        [{\"orientation\": \"h\", \"type\": \"bar\", \"x\": [1759, 1657, 2969], \"y\": [\"Normal\", \"Berita Bohong\", \"HateSpeech\", \"Offensive\"]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d22a558c-0542-4d4a-9d71-cce04353adc1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11v63yFWKvyF"
      },
      "source": [
        "## TransferLearning Section menggunakan transformer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6eJ2s4rLF_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c60399-dffd-4cca-9d69-ffa6954018ce"
      },
      "source": [
        "# Check panjang text Narasi\n",
        "from collections import Counter\n",
        "seq_len = [len(text.split()) for text in dfAllData[\"tweet\"] if type(text) != float]\n",
        "print(Counter(seq_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({6: 471, 7: 464, 5: 438, 9: 416, 8: 407, 12: 369, 10: 368, 11: 366, 13: 263, 14: 257, 15: 235, 18: 194, 16: 174, 17: 164, 19: 153, 20: 128, 23: 115, 21: 114, 22: 111, 24: 107, 27: 84, 26: 83, 25: 82, 29: 76, 28: 76, 31: 64, 30: 60, 32: 54, 35: 43, 34: 42, 33: 41, 36: 36, 37: 31, 39: 27, 41: 25, 40: 23, 38: 22, 42: 22, 43: 18, 44: 10, 45: 9, 46: 8, 48: 8, 47: 6, 57: 5, 84: 5, 54: 4, 59: 4, 74: 3, 75: 3, 52: 3, 55: 3, 110: 3, 98: 3, 108: 3, 61: 3, 58: 3, 93: 2, 96: 2, 120: 2, 88: 2, 79: 2, 69: 2, 114: 2, 76: 2, 62: 2, 53: 2, 116: 2, 115: 2, 49: 2, 68: 2, 121: 2, 67: 2, 135: 2, 89: 2, 82: 2, 131: 2, 70: 2, 77: 1, 97: 1, 51: 1, 64: 1, 56: 1, 173: 1, 107: 1, 102: 1, 118: 1, 87: 1, 123: 1, 104: 1, 66: 1, 112: 1, 81: 1, 127: 1, 128: 1, 60: 1, 92: 1, 124: 1, 148: 1, 85: 1, 113: 1, 122: 1, 111: 1, 73: 1, 141: 1, 171: 1, 164: 1, 50: 1, 169: 1, 159: 1, 119: 1, 133: 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCH2KLg5Nsbq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "f9ddfda2-4bbd-4034-8062-da6c61d29ee3"
      },
      "source": [
        "plt.figure(figsize=(18,12))\n",
        "sns.histplot(list(dict(Counter(seq_len)).values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc988a652d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX0HNNtlMbFc"
      },
      "source": [
        "METRICS = [\n",
        "        tf.keras.metrics.TruePositives(name='tp'),\n",
        "        tf.keras.metrics.FalsePositives(name='fp'),\n",
        "        tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "        tf.keras.metrics.FalseNegatives(name='fn'), \n",
        "        tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxUeP-nIMTeO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "45c9d660-9c86-48f9-c8bf-90c895bc989a"
      },
      "source": [
        "WORD_SIZE = 5000\n",
        "def dataForLstm():\n",
        "  from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "  tokenizer = Tokenizer(num_words = WORD_SIZE)\n",
        "  tokenizer.fit_on_texts(dfAllData[\"tweet\"].values)\n",
        "  X = tokenizer.texts_to_sequences(dfAllData[\"tweet\"].values)\n",
        "  X = tf.keras.preprocessing.sequence.pad_sequences(X,maxlen=MAX_LENGTHS)\n",
        "  Ylstm = tf.keras.utils.to_categorical(dfAllData[\"labels\"])\n",
        "  #x_trainlstm,x_valLstm,y_trainlstm,y_valLstm = train_test_split(X,Ylstm,test_size=0.2,random_state=1)\n",
        "  #return x_trainlstm,x_valLstm,y_trainlstm,y_valLstm\n",
        "  return X,Ylstm\n",
        "\"\"\"from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words = WORD_SIZE)\n",
        "tokenizer.fit_on_texts(dfAllData[\"tweet\"].values)\n",
        "X = tokenizer.texts_to_sequences(dfAllData[\"tweet\"].values)\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X)\n",
        "Ylstm = tf.keras.utils.to_categorical(dfAllData[\"labels\"])\n",
        "#x_trainlstm,x_valLstm,y_trainlstm,y_valLstm = train_test_split(X,Ylstm,test_size=0.001,random_state=1)\n",
        "tokenizer.sequences_to_texts([x_trainlstm[0]])\n",
        "#return x_trainlstm,x_valLstm,y_trainlstm,y_valLstm\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'from tensorflow.keras.preprocessing.text import Tokenizer\\ntokenizer = Tokenizer(num_words = WORD_SIZE)\\ntokenizer.fit_on_texts(dfAllData[\"tweet\"].values)\\nX = tokenizer.texts_to_sequences(dfAllData[\"tweet\"].values)\\nX = tf.keras.preprocessing.sequence.pad_sequences(X)\\nYlstm = tf.keras.utils.to_categorical(dfAllData[\"labels\"])\\n#x_trainlstm,x_valLstm,y_trainlstm,y_valLstm = train_test_split(X,Ylstm,test_size=0.001,random_state=1)\\ntokenizer.sequences_to_texts([x_trainlstm[0]])\\n#return x_trainlstm,x_valLstm,y_trainlstm,y_valLstm'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6za2aPjDNymC"
      },
      "source": [
        "#Not Using its Attention to train.\n",
        "\n",
        "\n",
        "def dataforIndoBert():\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
        "\n",
        "  token_train = {\n",
        "      \"tweet\" : tokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "  data = {\n",
        "    \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train[\"tweet\"][\"input_ids\"])),\n",
        "  }\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "\n",
        "  return data[\"tweet\"].numpy(),Y\n",
        "\n",
        "\n",
        "def dataforRoberta():\n",
        "  RobertaModelName = \"cahya/roberta-base-indonesian-522M\"\n",
        "  RobertaTokenizer = AutoTokenizer.from_pretrained(RobertaModelName)\n",
        "  token_train_Roberta = {\n",
        "      \"tweet\" : RobertaTokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "\n",
        "  train_dataRoberta = {\n",
        "      \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train_Roberta[\"tweet\"][\"input_ids\"]))\n",
        "  }\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "\n",
        "  return train_dataRoberta[\"tweet\"].numpy(),Y\n",
        "\n",
        "\n",
        "def dataforBert():\n",
        "  BertModelName = \"cahya/bert-base-indonesian-522M\"\n",
        "  BertModelTokenizer = AutoTokenizer.from_pretrained(RobertaModelName)\n",
        "  token_train_bert = {\n",
        "      \"tweet\" : BertModelTokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "  train_databert = {\n",
        "      \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train_bert[\"tweet\"][\"input_ids\"]))\n",
        "  }\n",
        "\n",
        "\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "\n",
        "  return train_databert[\"tweet\"].numpy(),Y\n",
        "\n",
        "def dataforGPT2():\n",
        "  GPT2Modelname = \"cahya/gpt2-small-indonesian-522M\"\n",
        "  Gpt2ModelTokenizer = AutoTokenizer.from_pretrained(GPT2Modelname)\n",
        "  Gpt2ModelTokenizer.pad_token = Gpt2ModelTokenizer.eos_token\n",
        "  token_train_GPT2 = {\n",
        "      \"tweet\" : Gpt2ModelTokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          \n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "\n",
        "  train_dataGPT2 = {\n",
        "      \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train_GPT2[\"tweet\"][\"input_ids\"]))\n",
        "  }\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "\n",
        "  return train_dataGPT2[\"tweet\"].numpy(),Y\n",
        "def dataforXLMRoBERTa():\n",
        "\n",
        "  XLMRobertaName = \"jplu/tf-xlm-roberta-base\"\n",
        "  XLMRobertaMultiLingualTokenizer = AutoTokenizer.from_pretrained(XLMRobertaName)\n",
        "\n",
        "  token_train_XLMRoberta = {\n",
        "      \"tweet\" : XLMRobertaMultiLingualTokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "\n",
        "  train_dataXLMRoberta = {\n",
        "      \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train_XLMRoberta[\"tweet\"][\"input_ids\"]))\n",
        "  }\n",
        "\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "\n",
        "  return train_dataXLMRoberta[\"tweet\"].numpy(), Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J3XQEdzvTNJ"
      },
      "source": [
        "#Not Using its Attention to train.\n",
        "\n",
        "def dataforIndoBertAttention():\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
        "\n",
        "  token_train = {\n",
        "      \"tweet\" : tokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "  data = {\n",
        "    \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train[\"tweet\"][\"input_ids\"])),\n",
        "    \"tweetMask\" :  tf.squeeze(tf.convert_to_tensor(token_train[\"tweet\"][\"attention_mask\"]))\n",
        "  }\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "  data = {\n",
        "      \"tweet\" : data[\"tweet\"].numpy(),\n",
        "      \"tweetMask\" : data[\"tweet\"].numpy()\n",
        "  }\n",
        "  return data,Y\n",
        "\n",
        "\n",
        "def dataforRobertaAttention():\n",
        "  RobertaModelName = \"cahya/roberta-base-indonesian-522M\"\n",
        "  RobertaTokenizer = AutoTokenizer.from_pretrained(RobertaModelName)\n",
        "  token_train_Roberta = {\n",
        "      \"tweet\" : RobertaTokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "\n",
        "  train_dataRoberta = {\n",
        "      \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train_Roberta[\"tweet\"][\"input_ids\"])),\n",
        "       \"tweetMask\" :  tf.squeeze(tf.convert_to_tensor(token_train_Roberta[\"tweet\"][\"attention_mask\"]))\n",
        "  }\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "  train_dataRoberta = {\n",
        "      \"tweet\" : train_dataRoberta[\"tweet\"].numpy(),\n",
        "      \"tweetMask\" : train_dataRoberta[\"tweet\"].numpy()\n",
        "  }\n",
        "  return train_dataRoberta,Y\n",
        "\n",
        "\n",
        "def dataforBertAttentions():\n",
        "  BertModelName = \"cahya/bert-base-indonesian-522M\"\n",
        "  BertModelTokenizer = AutoTokenizer.from_pretrained(RobertaModelName)\n",
        "  token_train_bert = {\n",
        "      \"tweet\" : BertModelTokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "  train_databert = {\n",
        "      \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train_bert[\"tweet\"][\"input_ids\"])),\n",
        "      \"tweetMask\" :  tf.squeeze(tf.convert_to_tensor(token_train_bert[\"tweet\"][\"attention_mask\"]))\n",
        "  }\n",
        "\n",
        "\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "  train_databert = {\n",
        "      \"tweet\" : train_databert[\"tweet\"].numpy(),\n",
        "      \"tweetMask\" : train_databert[\"tweet\"].numpy()\n",
        "  }\n",
        "  return train_databert,Y\n",
        "\n",
        "def dataforGPT2Attentions():\n",
        "  GPT2Modelname = \"cahya/gpt2-small-indonesian-522M\"\n",
        "  Gpt2ModelTokenizer = AutoTokenizer.from_pretrained(GPT2Modelname)\n",
        "  Gpt2ModelTokenizer.pad_token = Gpt2ModelTokenizer.eos_token\n",
        "  token_train_GPT2 = {\n",
        "      \"tweet\" : Gpt2ModelTokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          \n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "\n",
        "  train_dataGPT2 = {\n",
        "      \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train_GPT2[\"tweet\"][\"input_ids\"])),\n",
        "      \"tweetMask\" :  tf.squeeze(tf.convert_to_tensor(token_train_GPT2[\"tweet\"][\"attention_mask\"]))\n",
        "  }\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "  train_dataGPT2 = {\n",
        "      \"tweet\" : train_dataGPT2[\"tweet\"].numpy(),\n",
        "      \"tweetMask\" : train_dataGPT2[\"tweet\"].numpy()\n",
        "  }\n",
        "  return train_dataGPT2,Y\n",
        "def dataforXLMRoBERTaAttention():\n",
        "\n",
        "  XLMRobertaName = \"jplu/tf-xlm-roberta-base\"\n",
        "  XLMRobertaMultiLingualTokenizer = AutoTokenizer.from_pretrained(XLMRobertaName)\n",
        "\n",
        "  token_train_XLMRoberta = {\n",
        "      \"tweet\" : XLMRobertaMultiLingualTokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "\n",
        "  train_dataXLMRoberta = {\n",
        "      \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train_XLMRoberta[\"tweet\"][\"input_ids\"])),\n",
        "      \"tweetMask\" :  tf.squeeze(tf.convert_to_tensor(token_train_XLMRoberta[\"tweet\"][\"attention_mask\"]))\n",
        "  }\n",
        "\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "  train_dataXLMRoberta = {\n",
        "      \"tweet\" : train_dataXLMRoberta[\"tweet\"].numpy(),\n",
        "      \"tweetMask\" : train_dataXLMRoberta[\"tweet\"].numpy()\n",
        "  }\n",
        "  return train_dataXLMRoberta, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PREO67yqnCk1"
      },
      "source": [
        "## Architecture\n",
        "def architectureTransformers(passedModel):\n",
        "  METRICS = [\n",
        "        tf.keras.metrics.TruePositives(name='tp'),\n",
        "        tf.keras.metrics.FalsePositives(name='fp'),\n",
        "        tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "        tf.keras.metrics.FalseNegatives(name='fn'), \n",
        "        tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "  ]\n",
        "\n",
        "  ids1 = tf.keras.layers.Input(shape=(MAX_LENGTHS,),dtype=tf.int32,name=\"tweet\")\n",
        "  #attentions = tf.keras.layers.Input(shape=(MAX_LENGTHS,),dtype=tf.int32,name=\"tweetMask\")\n",
        "  last_hidden_state, pooler_output = passedModel(ids1).to_tuple()\n",
        "  layers = tf.keras.layers.Flatten()(last_hidden_state)\n",
        "  layers = tf.keras.layers.Dropout(0.3)(layers)\n",
        "  layers = tf.keras.layers.Dense(1024,activation=tf.nn.relu)(layers)\n",
        "  layers = tf.keras.layers.Dense(128,activation=tf.nn.relu)(layers)\n",
        "  layers = tf.keras.layers.Dropout(0.3)(layers)\n",
        "  fin_layer = tf.keras.layers.Dense(NUM_CATEGORICAL,activation= tf.nn.softmax)(layers)\n",
        "\n",
        "  final = tf.keras.Model(inputs=[ids1],outputs=[fin_layer])\n",
        "  \n",
        "  for layer in final.layers:\n",
        "      layer.trainable = False\n",
        "  for layer in final.layers[2:]:\n",
        "    layer.trainable = True \n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=.0001)\n",
        "  final.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=optimizer,metrics = METRICS)\n",
        "\n",
        "  return final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CzneSQ_W0hR"
      },
      "source": [
        "METRICS = [\n",
        "        tf.keras.metrics.TruePositives(name='tp'),\n",
        "        tf.keras.metrics.FalsePositives(name='fp'),\n",
        "        tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "        tf.keras.metrics.FalseNegatives(name='fn'), \n",
        "        tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.AUC(name='auc'),]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDBms5E_SgAR"
      },
      "source": [
        "def indoBertModelAttention():\n",
        "  ids1 = tf.keras.layers.Input(shape=(MAX_LENGTHS,),dtype=tf.int32,name=\"tweet\")\n",
        "  attention = tf.keras.layers.Input(shape=(MAX_LENGTHS,),dtype=tf.int32,name=\"tweetMask\")\n",
        "\n",
        "  last_hidden_state, pooler_output = IndoBert(ids1,attention_mask=attention).to_tuple()\n",
        "  layers = tf.keras.layers.Flatten()(last_hidden_state)\n",
        "  layers = tf.keras.layers.Dense(units=500,activation=tf.nn.relu)(layers)\n",
        "\n",
        "  layers = tf.keras.layers.Dense(128,activation=tf.nn.relu)(layers)\n",
        "  layers = tf.keras.layers.Dropout(0.3)(layers)\n",
        "  fin_layer = tf.keras.layers.Dense(NUM_CATEGORICAL,activation= tf.nn.softmax)(layers)\n",
        "\n",
        "  final = tf.keras.Model(inputs=[ids1,attention],outputs=[fin_layer])\n",
        "  \n",
        "  for layer in final.layers:\n",
        "      layer.trainable = False\n",
        "  for layer in final.layers[2:]:\n",
        "    layer.trainable = True \n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=.01)\n",
        "  final.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=optimizer,metrics = METRICS)\n",
        "\n",
        "  return final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfzO9XPhOmZg"
      },
      "source": [
        "## LSTM MODELS basic Attentions\n",
        "RNN_CELL_SIZE = 32\n",
        "class Attention(tf.keras.Model):\n",
        "  def __init__(self,units):\n",
        "    super(Attention,self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "  \n",
        "  def call(self,features,hidden):\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "\n",
        "    score = tf.nn.tanh(\n",
        "        self.W1(features) + self.W2(hidden_with_time_axis)\n",
        "    )\n",
        "    attention_weights = tf.nn.softmax(self.V(score), axis = 1)\n",
        "\n",
        "    context_vector = attention_weights * features\n",
        "    context_vector = tf.reduce_sum(context_vector, axis= 1)\n",
        "    return context_vector, attention_weights\n",
        "def attentionLayer():\n",
        "  sequence_input = tf.keras.Input(shape=(MAX_LENGTHS,),dtype=tf.int32)\n",
        "  embedded_sequences = tf.keras.layers.Embedding(WORD_SIZE, MAX_LENGTHS)(sequence_input)\n",
        "  lstmLayer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(RNN_CELL_SIZE, return_sequences=True),name= \"bi_lstm\")(embedded_sequences)\n",
        "  (lstm,forward_h, forward_c, backward_h, backward_c) = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(RNN_CELL_SIZE,return_state=True), name=\"bi_lstm_1\")(lstmLayer)\n",
        "  state_h = tf.keras.layers.Concatenate()([forward_h,backward_h])\n",
        "  state_c = tf.keras.layers.Concatenate()([forward_c,backward_c])\n",
        "  context_vector ,attention_weights = Attention(10)(lstm,state_h)\n",
        "  dense = tf.keras.layers.Dense(20 ,activation = tf.nn.relu)(context_vector)\n",
        "  dense = tf.keras.layers.Dropout(0.10)(dense)\n",
        "  output = tf.keras.layers.Dense(4, activation = tf.nn.softmax)(dense)\n",
        "\n",
        "  model = tf.keras.Model(inputs = [sequence_input], outputs = output)\n",
        "  print(model.summary())\n",
        "  tf.keras.utils.plot_model(model, show_shapes=True, dpi=90)\n",
        "  model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer='adam',\n",
        "              metrics=METRICS)\n",
        "  return model\n",
        "#x_dataLstm,x_valLstm,y_dataLstm,y_valLstm = dataForLstm()\n",
        "#model = attentionLayer()\n",
        "#EPOCHS = 5\n",
        "#history = model.fit(x_dataLstm,y_dataLstm,\n",
        "#                    batch_size=64,\n",
        "#                    epochs=EPOCHS,\n",
        "#                    validation_split=0.2)\n",
        "\n",
        "def lstmModel(X):\n",
        "  input_lstm = tf.keras.layers.Input(shape=(X,),dtype = tf.int32,name=\"tweet\")\n",
        "  layers  = tf.keras.layers.Embedding(WORD_SIZE,23 )(input_lstm)\n",
        "  layers = tf.keras.layers.SpatialDropout1D(0.4)(layers)\n",
        "  layers = tf.keras.layers.LSTM(64, activation=tf.nn.tanh,dropout = 0.4,recurrent_dropout=0.2,)(layers)\n",
        "  layers = tf.keras.layers.Dense(128,activation=tf.nn.relu)(layers)\n",
        "  output = tf.keras.layers.Dense(NUM_CATEGORICAL,activation=tf.nn.softmax)(layers)\n",
        "  \n",
        "  model = tf.keras.Model(inputs= [input_lstm], outputs = [output])\n",
        "\n",
        "  model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "                metrics = METRICS)\n",
        "  return model\n",
        "\n",
        "def lstmBidirectional(X):\n",
        "  input_lstm = tf.keras.layers.Input(shape=(X,),dtype = tf.int32,name=\"tweet\")\n",
        "  layers  = tf.keras.layers.Embedding(WORD_SIZE,23 )(input_lstm)\n",
        "  layers = tf.keras.layers.SpatialDropout1D(0.4)(layers)\n",
        "  layers = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation=tf.nn.tanh,dropout = 0.4,recurrent_dropout=0.2))(layers)\n",
        "  layers = tf.keras.layers.Dense(128,activation=tf.nn.relu)(layers)\n",
        "  output = tf.keras.layers.Dense(NUM_CATEGORICAL,activation=tf.nn.softmax)(layers)\n",
        "  \n",
        "  model = tf.keras.Model(inputs= [input_lstm], outputs = [output])\n",
        "\n",
        "  model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "                metrics = METRICS)\n",
        "  return model\n",
        "#x_trainlstm,x_valLstm,y_trainlstm,y_valLstm = dataForLstm()\n",
        "#model = lstmModel(142)\n",
        "#EPOCHS = 10\n",
        "#history = model.fit(x=x_trainlstm,y=y_trainlstm ,validation_data = (x_valLstm,y_valLstm),batch_size=64,epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "VtVoNIjSKY7Z",
        "outputId": "0ff98a10-f900-4a37-cbee-f94d5d72ae63"
      },
      "source": [
        "\"\"\"pred = model.predict(X)\n",
        "def getDifferTrainingLSTM(dat,y_train,pred):\n",
        "  y_train = np.argmax(y_train,axis=1)\n",
        "  pred = np.argmax(pred,axis=1)\n",
        "  print(pred)\n",
        "  differ = []\n",
        "  for indx,content in enumerate(dat[:,0]):\n",
        "     if (y_train[indx] != pred[indx]):\n",
        "       differ.append( (indx,tokenizer.sequences_to_texts(dat[[indx]]),y_train[indx],pred[indx] ))\n",
        "  return differ\n",
        "pd.DataFrame(getDifferTrainingLSTM(X,Ylstm,pred)).to_excel(\"Klasifikasi yang SalahLSTM.xlsx\",index=False)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pred = model.predict(X)\\ndef getDifferTrainingLSTM(dat,y_train,pred):\\n  y_train = np.argmax(y_train,axis=1)\\n  pred = np.argmax(pred,axis=1)\\n  print(pred)\\n  differ = []\\n  for indx,content in enumerate(dat[:,0]):\\n     if (y_train[indx] != pred[indx]):\\n       differ.append( (indx,tokenizer.sequences_to_texts(dat[[indx]]),y_train[indx],pred[indx] ))\\n  return differ\\npd.DataFrame(getDifferTrainingLSTM(X,Ylstm,pred)).to_excel(\"Klasifikasi yang SalahLSTM.xlsx\",index=False)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "wmNsknd3XHlz",
        "outputId": "001919bf-a983-4c1d-98b6-4786f7691a7b"
      },
      "source": [
        "\"\"\"def changeTheLabels(df1,df2):\n",
        "  for i in (df2.loc[:,3]):\n",
        "    print(i)\n",
        "    if (df1.loc[i,\"labels\"] != df2.loc[i,3]):\n",
        "      df1.loc[i,\"labels\"] = df2.loc[i,3]\n",
        "  print(\"changed Succesfully blok\")\n",
        "copyDfAllData = dfAllData.copy()\n",
        "changeTheLabels(copyDfAllData,checkitBrot)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def changeTheLabels(df1,df2):\\n  for i in (df2.loc[:,3]):\\n    print(i)\\n    if (df1.loc[i,\"labels\"] != df2.loc[i,3]):\\n      df1.loc[i,\"labels\"] = df2.loc[i,3]\\n  print(\"changed Succesfully blok\")\\ncopyDfAllData = dfAllData.copy()\\nchangeTheLabels(copyDfAllData,checkitBrot)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Yrko3BhHayAV",
        "outputId": "c539f846-57b5-49b1-b405-5b3e5bcaccb9"
      },
      "source": [
        "\"\"\"copyDfAllData.to_csv(\"DataSwapped.csv\",index=False)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'copyDfAllData.to_csv(\"DataSwapped.csv\",index=False)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qn1zctuKNkVn",
        "outputId": "2a84bc83-a14c-41cf-fb6f-b0280f5fe33c"
      },
      "source": [
        "\"\"\"checkitBrot = pd.read_excel(\"Klasifikasi yang SalahLSTM.xlsx\")\n",
        "checkitBrot\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'checkitBrot = pd.read_excel(\"Klasifikasi yang SalahLSTM.xlsx\")\\ncheckitBrot'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CjvC-VBFFEl"
      },
      "source": [
        "def initLstm(X):\n",
        "    return [lstmModel(X),lstmBidirectional(X)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "dsb6LUB5E6Ge",
        "outputId": "f96a95bf-022b-4dde-bc79-06fb19238208"
      },
      "source": [
        "FinalHistory_lstm = []\n",
        "trainedLstmModels = []\n",
        "splits = 5\n",
        "EPOCHS = 8\n",
        "\n",
        "def TrainLSTModels(splits,EPOCHS):\n",
        "    from sklearn.model_selection import StratifiedShuffleSplit\n",
        "    skf = StratifiedShuffleSplit(n_splits=splits,random_state=10)\n",
        "    modelNames = [\"LSTM\",\"LSTM Bidirectional\"]\n",
        "    lstm,lstmBd = initLstm(MAX_LENGTHS)\n",
        "    lstmModels = [lstm,lstmBd]\n",
        "    Xdat,Ydat = dataForLstm()\n",
        "    fold = 1\n",
        "    for modelname, model in zip(modelNames,lstmModels):\n",
        "        HISTORY_LSTM = []\n",
        "        for train_indx, val_indx in skf.split(Xdat,np.argmax(Ydat,axis=1)):\n",
        "            print(\"============================================\")\n",
        "            print(f\"TRAINING {modelname} : , {fold}\" )\n",
        "            if(modelname == \"LSTM\"):\n",
        "              model = lstmModel(MAX_LENGTHS)\n",
        "            elif(modelname == \"LSTM Bidirectional\"):\n",
        "              model = lstmBidirectional(MAX_LENGTHS)\n",
        "            tf.keras.backend.clear_session()\n",
        "            train = Xdat[train_indx]\n",
        "            val = Xdat[val_indx]\n",
        "            ytrain = Ydat[train_indx] \n",
        "            yval = Ydat[val_indx]\n",
        "            trainData = (tf.data.Dataset.from_tensor_slices((train,ytrain))).batch(64).prefetch(AUTO)\n",
        "            valData = (tf.data.Dataset.from_tensor_slices((val,yval))).batch(64).prefetch(AUTO).cache()\n",
        "            history = model.fit( (trainData),validation_data = valData,epochs=EPOCHS)\n",
        "            #print(f\"Scores For fold {fold} ACC {history.history['accuracy'].mean()} , VAL ACC {history.history['val_accuracy'].mean()}\")\n",
        "            data = (\"rataAccTrain\", \"rataAccVal\",\n",
        "                    \"rataLossTrain\", \"rataLossVal\",\n",
        "                    \"precisionTrain\",\"precisionVal\",\n",
        "                    \"recallTrain\",\"recallVal\",\"f1ScoreTrain\",\"f1ScoreVal\")\n",
        "            datBang = [ (np.mean(history.history[\"accuracy\"]), np.mean(history.history[\"val_accuracy\"]),\n",
        "                         np.mean(history.history[\"loss\"]), np.mean(history.history[\"val_loss\"]),\n",
        "                         np.mean(history.history[\"precision\"]), np.mean(history.history[\"val_precision\"]),\n",
        "                         np.mean(history.history[\"recall\"]), np.mean(history.history[\"val_recall\"]) )  ]\n",
        "            HISTORY_LSTM.append(datBang)\n",
        "            fold += 1\n",
        "        hist = np.array(HISTORY_LSTM,dtype=np.float32).reshape(splits,8)\n",
        "        data = (hist[:,0].mean(),hist[:,1].mean(),hist[:,2].mean(),\n",
        "                hist[:,3].mean(),hist[:,4].mean(),hist[:,5].mean(),\n",
        "                hist[:,6].mean(),hist[:,7].mean(),modelname)\n",
        "        FinalHistory_lstm.append((data))\n",
        "        trainedLstmModels.append(model)\n",
        "TrainLSTModels(splits,EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-63583a034f77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mFinalHistory_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtrainedLstmModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mTrainLSTModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-63583a034f77>\u001b[0m in \u001b[0;36mTrainLSTModels\u001b[0;34m(splits, EPOCHS)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodelNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"LSTM\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"LSTM Bidirectional\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlstmBd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitLstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LENGTHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlstmModels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlstmBd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mXdat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataForLstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'initLstm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvL2eHPsfkpB"
      },
      "source": [
        "dfResultLstm = pd.DataFrame(FinalHistory_lstm,columns=[ \"rataAccTrain\", \"rataAccVal\",\n",
        "                    \"rataLossTrain\", \"rataLossVal\",\n",
        "                    \"precisionTrain\",\"precisionVal\",\n",
        "                    \"recallTrain\",\"recallVal\",\"ModelName\"])\n",
        "dfResultLstm.to_excel(\"ResultLstmMerged.xlsx\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "EBK0Jrjsf_tG",
        "outputId": "377264da-3be5-4a80-ec50-71b65a2b1fdf"
      },
      "source": [
        "dfResultLstm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rataAccTrain</th>\n",
              "      <th>rataAccVal</th>\n",
              "      <th>rataLossTrain</th>\n",
              "      <th>rataLossVal</th>\n",
              "      <th>precisionTrain</th>\n",
              "      <th>precisionVal</th>\n",
              "      <th>recallTrain</th>\n",
              "      <th>recallVal</th>\n",
              "      <th>ModelName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.893532</td>\n",
              "      <td>0.883294</td>\n",
              "      <td>0.264713</td>\n",
              "      <td>0.308206</td>\n",
              "      <td>0.908158</td>\n",
              "      <td>0.887490</td>\n",
              "      <td>0.871699</td>\n",
              "      <td>0.879499</td>\n",
              "      <td>LSTM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.893045</td>\n",
              "      <td>0.881221</td>\n",
              "      <td>0.274335</td>\n",
              "      <td>0.334894</td>\n",
              "      <td>0.906887</td>\n",
              "      <td>0.883491</td>\n",
              "      <td>0.873026</td>\n",
              "      <td>0.876213</td>\n",
              "      <td>LSTM Bidirectional</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rataAccTrain  rataAccVal  ...  recallVal           ModelName\n",
              "0      0.893532    0.883294  ...   0.879499                LSTM\n",
              "1      0.893045    0.881221  ...   0.876213  LSTM Bidirectional\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WB8W28EXPLd"
      },
      "source": [
        "# Using its Attention to train.\n",
        "\n",
        "def dataforIndoBert():\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
        "\n",
        "  token_train = {\n",
        "      \"tweet\" : tokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "  data = {\n",
        "    \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train[\"tweet\"][\"input_ids\"])),\n",
        "  }\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "\n",
        "  return data[\"tweet\"].numpy(),Y\n",
        "\n",
        "\n",
        "def dataforRoberta():\n",
        "  RobertaModelName = \"cahya/roberta-base-indonesian-522M\"\n",
        "  RobertaTokenizer = AutoTokenizer.from_pretrained(RobertaModelName)\n",
        "  token_train_Roberta = {\n",
        "      \"tweet\" : RobertaTokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "\n",
        "  train_dataRoberta = {\n",
        "      \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train_Roberta[\"tweet\"][\"input_ids\"]))\n",
        "  }\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "\n",
        "  return train_dataRoberta[\"tweet\"].numpy(),Y\n",
        "\n",
        "\n",
        "def dataforBert():\n",
        "  BertModelName = \"cahya/bert-base-indonesian-522M\"\n",
        "  BertModelTokenizer = AutoTokenizer.from_pretrained(RobertaModelName)\n",
        "  token_train_bert = {\n",
        "      \"tweet\" : BertModelTokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "  train_databert = {\n",
        "      \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train_bert[\"tweet\"][\"input_ids\"]))\n",
        "  }\n",
        "\n",
        "\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "\n",
        "  return train_databert[\"tweet\"].numpy(),Y\n",
        "\n",
        "def dataforGPT2():\n",
        "  GPT2Modelname = \"cahya/gpt2-small-indonesian-522M\"\n",
        "  Gpt2ModelTokenizer = AutoTokenizer.from_pretrained(GPT2Modelname)\n",
        "  Gpt2ModelTokenizer.pad_token = Gpt2ModelTokenizer.eos_token\n",
        "  token_train_GPT2 = {\n",
        "      \"tweet\" : Gpt2ModelTokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          \n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "\n",
        "  train_dataGPT2 = {\n",
        "      \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train_GPT2[\"tweet\"][\"input_ids\"]))\n",
        "  }\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "\n",
        "  return train_dataGPT2[\"tweet\"].numpy(),Y\n",
        "def dataforXLMRoBERTa():\n",
        "\n",
        "  XLMRobertaName = \"jplu/tf-xlm-roberta-base\"\n",
        "  XLMRobertaMultiLingualTokenizer = AutoTokenizer.from_pretrained(XLMRobertaName)\n",
        "\n",
        "  token_train_XLMRoberta = {\n",
        "      \"tweet\" : XLMRobertaMultiLingualTokenizer.batch_encode_plus(\n",
        "          dfAllData[\"tweet\"].to_list(),\n",
        "          max_length = MAX_LENGTHS,\n",
        "          pad_to_max_length = True,\n",
        "          truncation = True\n",
        "      ),\n",
        "  }\n",
        "\n",
        "  train_dataXLMRoberta = {\n",
        "      \"tweet\" : tf.squeeze(tf.convert_to_tensor(token_train_XLMRoberta[\"tweet\"][\"input_ids\"]))\n",
        "  }\n",
        "\n",
        "  Y = tf.convert_to_tensor(dfAllData[\"labels\"])\n",
        "  Y = to_categorical(Y,NUM_CATEGORICAL)\n",
        "\n",
        "  return train_dataXLMRoberta[\"tweet\"].numpy(), Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935,
          "referenced_widgets": [
            "2f4e583fb63741e6bd86e21a6a770513",
            "9b2ab22d7ed94a5ca36f3e44347bcaa2",
            "f12c01f1496941919dc8fcbd438b2019",
            "8181c076d9b54bdb99e787ef5bfad760",
            "2f2a3d25dfd44390890e30e687a87673",
            "57e4f3547d4d422bb87f88b4f80595e8",
            "0bfa4206796344eca438fc3398f55141",
            "b451434baaf14dc093c92d8f8abc6bae",
            "1f56dcda3ac7440a887b3a1c1ac1b2a6",
            "2c071e6736d6472aa4276ad183054a45",
            "0db91c7c3b2e428ea0f8359bf640d8ab",
            "b28e4b34521d483aacb96b142fbc7c27",
            "244e91680b4e48ee97f1f61443f5b3d3",
            "f754979bf6b140678dab592efb733fad",
            "08ad2db7d3f74d568969c303ebe310ae",
            "d23428b37e784af2865370d0681bdd1c",
            "b8ecabce6c5e4dc48fecf6e2e9d16381",
            "54710d233e004a818092f2c833d85270",
            "1906ebe7e70e4052a4af42395a7269ba",
            "a746499e302041b3bc8bebddeabb18e5",
            "7714a4e4d5284dbfaecdd456d8f72885",
            "2df1a17306c5460fb256723291e1190c",
            "9cd5ab3622404253a3b50f877d427fed",
            "ea0e4eca556c4a9199069739f42d4245",
            "72284e9ed1cb4d5c868af3cb28b7a96e",
            "38962294dfe245c2acd5cabfa3b67b37",
            "bcabce0f6f0d40bea9d3f47a81915193",
            "d6bceda25c414883baa6de6518de7e49",
            "af48306e91c44c919092449425c3d92f",
            "e8d42c0869524761af92aab581a56165",
            "99b67f2a5a0641efae500aac57baddf8",
            "a5b86f04ec7c45d6b9ae25f23f921134",
            "946da461b84241468697c518667b2759",
            "d2c278ff1ed741ffa27607f4bffcab97",
            "2f182570eda547f986e52924933053e8",
            "c94abdc96a714131af2785ece5e3a0fc",
            "4bf16fb47cd84ec68cbad4e2f7e0401b",
            "03d72253449f4630bdc1aca9ba5b9a39",
            "e6c31ef3d48d43cba07f9438a9da4a61",
            "58fe91c6a7884a86aead86800b3169c4",
            "c605ded2f9934524aa450d211c3906ab",
            "b8d4432c6aea42f99d21326b4e57b04b",
            "ffef895755924ed0851aaab96beec4e5",
            "afb274e08cb6471886da11b89ab659a1",
            "fbcda1620e924ea8b7f1cebd14f5ec79",
            "044d70c68bc1452c8fde0743735d26af",
            "0d43dd761c2b4d559a1dbc325e59370c",
            "3a901f80a9ea4bdc9906360ebc08f630",
            "899dbdfa0abf4c7ea2d2d535feffdd49",
            "78e68979629d47ac89a85e2acb45181b",
            "900a0714c6194c299003c34022d6bba6",
            "d82ef5ed0d6e41b6a8a929a9bfc44883",
            "6213930b9a5e4acc8142687e6688e1be",
            "744df59738a445ce814caf40570f4d5d",
            "e60c74eb0e624ae0bf681e40833e4256",
            "d40c0111e83842c9a3382b1657a4df6b",
            "8d20b7bba73a4003aa2b1484b1c969b1",
            "8aa733c51efb45ff87c0ae72e32199fc",
            "554ecafdc260418698a8b26ffa9b3d26",
            "c214f43252b649df8bd4591dea496c97",
            "31172506414f447eac34d89ff608d504",
            "ec2325ffefd440f9a222846e163a25ea",
            "a10f6c1e6469459482b77fe43f2c5e27",
            "d17aa873854f4bf8ae23821c4de04372",
            "3e57e10f8039455d8fa0821d4e9ea538",
            "5ad5ebdc8f434d0b93e8de318ead4384",
            "8b0995a0ccb84cc69287c0902e23c445",
            "6d1798b156044dda800d51bcfdc24b4f",
            "07fde35a6c654a6d8197b77da74f8179",
            "199728cf370b423b81a30a183da89636",
            "dc2145f1ca524564a16e00a8ad09c2ca",
            "08ccfd49b99b4e54810ff17eb0c002a9",
            "32e4044e736449c18664e71d2af37891",
            "8fd3e33e6fef4e4587779fc45c61f0fa",
            "3c3474c6353e4c18ad30548e742466fb",
            "6ed1605ec9a54b0cb9e739e0f0fba113",
            "d90d6f832ba844cba4e16e44ae18fbc0",
            "e98e5e1fe631412a819905b76b709cfc",
            "629e01d828464d2cb9df5adefcfa2d62",
            "fa8bf4b57ccf4422bdfa8c0f24531c15"
          ]
        },
        "id": "JsbPXiLEqRXY",
        "outputId": "9b149bab-5850-4bde-83c6-de021ac5ce66"
      },
      "source": [
        "\n",
        "IndoBert = TFAutoModel.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
        "\n",
        "RobertaModelName = \"cahya/roberta-base-indonesian-522M\"\n",
        "RobertaModel = TFAutoModel.from_pretrained(RobertaModelName)\n",
        "\n",
        "BertModelName = \"cahya/bert-base-indonesian-522M\"\n",
        "BertModel = TFAutoModel.from_pretrained(BertModelName)\n",
        "\n",
        "XLMRobertaName = \"jplu/tf-xlm-roberta-base\"\n",
        "XLMRobertaMultiLingualModel = TFAutoModel.from_pretrained(XLMRobertaName)\n",
        "\n",
        "GPT2Modelname = \"cahya/gpt2-small-indonesian-522M\"\n",
        "Gpt2Model = TFAutoModel.from_pretrained(GPT2Modelname)\n",
        "\n",
        "def indoBertModel():\n",
        "  return architectureTransformers(IndoBert)\n",
        "\n",
        "def robertaModel():\n",
        "  model = architectureTransformers(RobertaModel)\n",
        "  return model\n",
        "\n",
        "def bertModel():\n",
        "  model = architectureTransformers(BertModel)\n",
        "  return model\n",
        "\n",
        "def GPT2Model():\n",
        "  return architectureTransformers(Gpt2Model)\n",
        "\n",
        "def XlmRoberta():\n",
        "  return architectureTransformers(XLMRobertaMultiLingualModel)\n",
        "\n",
        "def initModel():\n",
        "  return bertModel(),indoBertModel(),robertaModel(),XlmRoberta(),GPT2Model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f4e583fb63741e6bd86e21a6a770513",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1534.0, style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f56dcda3ac7440a887b3a1c1ac1b2a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=655812184.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at indobenchmark/indobert-base-p2 were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at indobenchmark/indobert-base-p2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8ecabce6c5e4dc48fecf6e2e9d16381",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72284e9ed1cb4d5c868af3cb28b7a96e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=668101576.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at cahya/roberta-base-indonesian-522M were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at cahya/roberta-base-indonesian-522M.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "946da461b84241468697c518667b2759",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=468.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c605ded2f9934524aa450d211c3906ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=545136632.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at cahya/bert-base-indonesian-522M were not used when initializing TFBertModel: ['mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at cahya/bert-base-indonesian-522M.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "899dbdfa0abf4c7ea2d2d535feffdd49",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d20b7bba73a4003aa2b1484b1c969b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1885418496.0, style=ProgressStyle(descrâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at jplu/tf-xlm-roberta-base were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at jplu/tf-xlm-roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e57e10f8039455d8fa0821d4e9ea538",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=573.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32e4044e736449c18664e71d2af37891",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=497933648.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2Model.\n",
            "\n",
            "All the layers of TFGPT2Model were initialized from the model checkpoint at cahya/gpt2-small-indonesian-522M.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXb8opeqsht_",
        "outputId": "c83bc988-5963-430d-81d1-c7963b0f9982"
      },
      "source": [
        "FinalHistory_Transformers = []\n",
        "trainedTransformerModels = []\n",
        "splits = 5\n",
        "EPOCHS = 8\n",
        "\n",
        "def TrainAttentions(splits,EPOCHS):\n",
        "  from sklearn.model_selection import StratifiedShuffleSplit\n",
        "  skf = StratifiedShuffleSplit(n_splits=splits)\n",
        "\n",
        "  fold = 1\n",
        "  #y_train= np.argmax(y_train,axis=1)\n",
        "  historyList = [] \n",
        "  bertmodelObj,indobertModelObj,robertaModelObj,xlmRobertaModelObj,GPT2ModelObj = initModel()\n",
        "  modelNames = [\"IndoBert\",\"Roberta\",\"Bert\",\"GPT2\",\"XLMROBERTA\"]\n",
        "  modelTransformers = [indobertModelObj,robertaModelObj,bertmodelObj,GPT2Model,xlmRobertaModelObj]\n",
        "  dataTransformers = [dataforIndoBert(),dataforRoberta(),dataforBert(),dataforGPT2(),dataforXLMRoBERTa()]\n",
        "  #modelNames = [\"XLMROBERTA\"]\n",
        "  #modelTransformers = [xlmRobertaModelObj]\n",
        "  #dataTransformers = [dataforXLMRoBERTa()]\n",
        "  for modelname, model,content in zip(modelNames,modelTransformers,dataTransformers):\n",
        "    HISTORY_TRANSFORMERS = []\n",
        "    for train_indx, val_indx in skf.split(content[0],np.argmax(content[1],axis=1)):\n",
        "      print(\"============================================\")\n",
        "      print(f\"TRAINING {modelname} : , {fold}\" )\n",
        "      if (modelname == \"IndoBert\"):\n",
        "        model = indoBertModel()\n",
        "      elif (modelname==\"Roberta\"):\n",
        "        model = robertaModel()\n",
        "      elif (modelname == \"Bert\"):\n",
        "        model = bertModel()\n",
        "      elif (modelname == \"GPT2\"):\n",
        "        model = GPT2Model()\n",
        "      elif (modelname == \"XLMROBERTA\"):\n",
        "        model = XlmRoberta()\n",
        "      train = content[0][train_indx]\n",
        "      val = content[0][val_indx]\n",
        "\n",
        "      ytrain = content[1][train_indx] \n",
        "      yval = content[1][val_indx]\n",
        "      trainData = (tf.data.Dataset.from_tensor_slices((train,ytrain))).batch(64).prefetch(AUTO)\n",
        "      valData = (tf.data.Dataset.from_tensor_slices((val,yval))).batch(64).prefetch(AUTO).cache()\n",
        "      history = model.fit( (trainData),validation_data = valData,epochs=EPOCHS)\n",
        "      data = (\"rataAccTrain\", \"rataAccVal\",\n",
        "                    \"rataLossTrain\", \"rataLossVal\",\n",
        "                    \"precisionTrain\",\"precisionVal\",\n",
        "                    \"recallTrain\",\"recallVal\",\"f1ScoreTrain\",\"f1ScoreVal\")\n",
        "      datBang = [ (np.mean(history.history[\"accuracy\"]), np.mean(history.history[\"val_accuracy\"]),\n",
        "                         np.mean(history.history[\"loss\"]), np.mean(history.history[\"val_loss\"]),\n",
        "                         np.mean(history.history[\"precision\"]), np.mean(history.history[\"val_precision\"]),\n",
        "                         np.mean(history.history[\"recall\"]), np.mean(history.history[\"val_recall\"]) )  ]\n",
        "      HISTORY_TRANSFORMERS.append(datBang)\n",
        "      fold += 1\n",
        "    hist = np.array(HISTORY_TRANSFORMERS,dtype=np.float32).reshape(splits,EPOCHS)\n",
        "    data = (hist[:,0].mean(),hist[:,1].mean(),hist[:,2].mean(),\n",
        "                hist[:,3].mean(),hist[:,4].mean(),hist[:,5].mean(),\n",
        "                hist[:,6].mean(),hist[:,7].mean(),modelname)\n",
        "    FinalHistory_Transformers.append((data))\n",
        "    trainedTransformerModels.append(model)\n",
        "TrainAttentions(splits,EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning:\n",
            "\n",
            "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "============================================\n",
            "TRAINING IndoBert : , 1\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8826 - tp: 4006.0000 - fp: 1369.0000 - tn: 10123.0000 - fn: 1740.0000 - accuracy: 0.7285 - precision: 0.7453 - recall: 0.6972 - auc: 0.8731WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 38s 283ms/step - loss: 0.8826 - tp: 4006.0000 - fp: 1369.0000 - tn: 10123.0000 - fn: 1740.0000 - accuracy: 0.7285 - precision: 0.7453 - recall: 0.6972 - auc: 0.8731 - val_loss: 0.3751 - val_tp: 529.0000 - val_fp: 83.0000 - val_tn: 1195.0000 - val_fn: 110.0000 - val_accuracy: 0.8435 - val_precision: 0.8644 - val_recall: 0.8279 - val_auc: 0.9618\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 22s 248ms/step - loss: 0.3999 - tp: 4650.0000 - fp: 826.0000 - tn: 10666.0000 - fn: 1096.0000 - accuracy: 0.8322 - precision: 0.8492 - recall: 0.8093 - auc: 0.9564 - val_loss: 0.4166 - val_tp: 505.0000 - val_fp: 92.0000 - val_tn: 1186.0000 - val_fn: 134.0000 - val_accuracy: 0.8279 - val_precision: 0.8459 - val_recall: 0.7903 - val_auc: 0.9545\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 22s 249ms/step - loss: 0.3414 - tp: 4869.0000 - fp: 680.0000 - tn: 10812.0000 - fn: 877.0000 - accuracy: 0.8637 - precision: 0.8775 - recall: 0.8474 - auc: 0.9680 - val_loss: 0.3737 - val_tp: 526.0000 - val_fp: 90.0000 - val_tn: 1188.0000 - val_fn: 113.0000 - val_accuracy: 0.8372 - val_precision: 0.8539 - val_recall: 0.8232 - val_auc: 0.9612\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.3104 - tp: 4963.0000 - fp: 614.0000 - tn: 10878.0000 - fn: 783.0000 - accuracy: 0.8770 - precision: 0.8899 - recall: 0.8637 - auc: 0.9733 - val_loss: 0.3659 - val_tp: 524.0000 - val_fp: 100.0000 - val_tn: 1178.0000 - val_fn: 115.0000 - val_accuracy: 0.8263 - val_precision: 0.8397 - val_recall: 0.8200 - val_auc: 0.9625\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.2908 - tp: 4998.0000 - fp: 573.0000 - tn: 10919.0000 - fn: 748.0000 - accuracy: 0.8858 - precision: 0.8971 - recall: 0.8698 - auc: 0.9767 - val_loss: 0.3422 - val_tp: 543.0000 - val_fp: 76.0000 - val_tn: 1202.0000 - val_fn: 96.0000 - val_accuracy: 0.8654 - val_precision: 0.8772 - val_recall: 0.8498 - val_auc: 0.9688\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.2674 - tp: 5082.0000 - fp: 536.0000 - tn: 10956.0000 - fn: 664.0000 - accuracy: 0.8954 - precision: 0.9046 - recall: 0.8844 - auc: 0.9803 - val_loss: 0.3577 - val_tp: 541.0000 - val_fp: 78.0000 - val_tn: 1200.0000 - val_fn: 98.0000 - val_accuracy: 0.8654 - val_precision: 0.8740 - val_recall: 0.8466 - val_auc: 0.9662\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.2805 - tp: 5003.0000 - fp: 577.0000 - tn: 10915.0000 - fn: 743.0000 - accuracy: 0.8843 - precision: 0.8966 - recall: 0.8707 - auc: 0.9777 - val_loss: 0.3563 - val_tp: 546.0000 - val_fp: 76.0000 - val_tn: 1202.0000 - val_fn: 93.0000 - val_accuracy: 0.8685 - val_precision: 0.8778 - val_recall: 0.8545 - val_auc: 0.9665\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.2512 - tp: 5094.0000 - fp: 510.0000 - tn: 10982.0000 - fn: 652.0000 - accuracy: 0.8989 - precision: 0.9090 - recall: 0.8865 - auc: 0.9826 - val_loss: 0.3449 - val_tp: 543.0000 - val_fp: 77.0000 - val_tn: 1201.0000 - val_fn: 96.0000 - val_accuracy: 0.8623 - val_precision: 0.8758 - val_recall: 0.8498 - val_auc: 0.9677\n",
            "============================================\n",
            "TRAINING IndoBert : , 2\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.6748 - tp: 4072.0000 - fp: 1306.0000 - tn: 10186.0000 - fn: 1674.0000 - accuracy: 0.7383 - precision: 0.7572 - recall: 0.7087 - auc: 0.8933WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 38s 287ms/step - loss: 0.6748 - tp: 4072.0000 - fp: 1306.0000 - tn: 10186.0000 - fn: 1674.0000 - accuracy: 0.7383 - precision: 0.7572 - recall: 0.7087 - auc: 0.8933 - val_loss: 0.4028 - val_tp: 514.0000 - val_fp: 73.0000 - val_tn: 1205.0000 - val_fn: 125.0000 - val_accuracy: 0.8388 - val_precision: 0.8756 - val_recall: 0.8044 - val_auc: 0.9640\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.4116 - tp: 4610.0000 - fp: 887.0000 - tn: 10605.0000 - fn: 1136.0000 - accuracy: 0.8244 - precision: 0.8386 - recall: 0.8023 - auc: 0.9531 - val_loss: 0.4369 - val_tp: 478.0000 - val_fp: 42.0000 - val_tn: 1236.0000 - val_fn: 161.0000 - val_accuracy: 0.8576 - val_precision: 0.9192 - val_recall: 0.7480 - val_auc: 0.9640\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.3694 - tp: 4714.0000 - fp: 727.0000 - tn: 10765.0000 - fn: 1032.0000 - accuracy: 0.8432 - precision: 0.8664 - recall: 0.8204 - auc: 0.9624 - val_loss: 0.3168 - val_tp: 543.0000 - val_fp: 79.0000 - val_tn: 1199.0000 - val_fn: 96.0000 - val_accuracy: 0.8560 - val_precision: 0.8730 - val_recall: 0.8498 - val_auc: 0.9726\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.3062 - tp: 4928.0000 - fp: 617.0000 - tn: 10875.0000 - fn: 818.0000 - accuracy: 0.8754 - precision: 0.8887 - recall: 0.8576 - auc: 0.9741 - val_loss: 0.3098 - val_tp: 542.0000 - val_fp: 87.0000 - val_tn: 1191.0000 - val_fn: 97.0000 - val_accuracy: 0.8545 - val_precision: 0.8617 - val_recall: 0.8482 - val_auc: 0.9729\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.2994 - tp: 4999.0000 - fp: 581.0000 - tn: 10911.0000 - fn: 747.0000 - accuracy: 0.8820 - precision: 0.8959 - recall: 0.8700 - auc: 0.9753 - val_loss: 0.2684 - val_tp: 563.0000 - val_fp: 68.0000 - val_tn: 1210.0000 - val_fn: 76.0000 - val_accuracy: 0.8842 - val_precision: 0.8922 - val_recall: 0.8811 - val_auc: 0.9806\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.2724 - tp: 5061.0000 - fp: 535.0000 - tn: 10957.0000 - fn: 685.0000 - accuracy: 0.8949 - precision: 0.9044 - recall: 0.8808 - auc: 0.9794 - val_loss: 0.2623 - val_tp: 567.0000 - val_fp: 63.0000 - val_tn: 1215.0000 - val_fn: 72.0000 - val_accuracy: 0.8936 - val_precision: 0.9000 - val_recall: 0.8873 - val_auc: 0.9812\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.2572 - tp: 5088.0000 - fp: 506.0000 - tn: 10986.0000 - fn: 658.0000 - accuracy: 0.8982 - precision: 0.9095 - recall: 0.8855 - auc: 0.9818 - val_loss: 0.2739 - val_tp: 550.0000 - val_fp: 48.0000 - val_tn: 1230.0000 - val_fn: 89.0000 - val_accuracy: 0.8889 - val_precision: 0.9197 - val_recall: 0.8607 - val_auc: 0.9817\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.2607 - tp: 5103.0000 - fp: 509.0000 - tn: 10983.0000 - fn: 643.0000 - accuracy: 0.8984 - precision: 0.9093 - recall: 0.8881 - auc: 0.9808 - val_loss: 0.2585 - val_tp: 558.0000 - val_fp: 57.0000 - val_tn: 1221.0000 - val_fn: 81.0000 - val_accuracy: 0.8826 - val_precision: 0.9073 - val_recall: 0.8732 - val_auc: 0.9820\n",
            "============================================\n",
            "TRAINING IndoBert : , 3\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.7697 - tp: 3876.0000 - fp: 1244.0000 - tn: 10248.0000 - fn: 1870.0000 - accuracy: 0.7245 - precision: 0.7570 - recall: 0.6746 - auc: 0.8813WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 39s 289ms/step - loss: 0.7697 - tp: 3876.0000 - fp: 1244.0000 - tn: 10248.0000 - fn: 1870.0000 - accuracy: 0.7245 - precision: 0.7570 - recall: 0.6746 - auc: 0.8813 - val_loss: 0.4135 - val_tp: 545.0000 - val_fp: 85.0000 - val_tn: 1193.0000 - val_fn: 94.0000 - val_accuracy: 0.8623 - val_precision: 0.8651 - val_recall: 0.8529 - val_auc: 0.9606\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.4151 - tp: 4571.0000 - fp: 833.0000 - tn: 10659.0000 - fn: 1175.0000 - accuracy: 0.8244 - precision: 0.8459 - recall: 0.7955 - auc: 0.9522 - val_loss: 0.3946 - val_tp: 535.0000 - val_fp: 95.0000 - val_tn: 1183.0000 - val_fn: 104.0000 - val_accuracy: 0.8419 - val_precision: 0.8492 - val_recall: 0.8372 - val_auc: 0.9643\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.3681 - tp: 4727.0000 - fp: 752.0000 - tn: 10740.0000 - fn: 1019.0000 - accuracy: 0.8460 - precision: 0.8627 - recall: 0.8227 - auc: 0.9622 - val_loss: 0.4501 - val_tp: 503.0000 - val_fp: 129.0000 - val_tn: 1149.0000 - val_fn: 136.0000 - val_accuracy: 0.7887 - val_precision: 0.7959 - val_recall: 0.7872 - val_auc: 0.9449\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.3301 - tp: 4876.0000 - fp: 645.0000 - tn: 10847.0000 - fn: 870.0000 - accuracy: 0.8658 - precision: 0.8832 - recall: 0.8486 - auc: 0.9696 - val_loss: 0.3915 - val_tp: 533.0000 - val_fp: 105.0000 - val_tn: 1173.0000 - val_fn: 106.0000 - val_accuracy: 0.8357 - val_precision: 0.8354 - val_recall: 0.8341 - val_auc: 0.9603\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.2774 - tp: 5055.0000 - fp: 563.0000 - tn: 10929.0000 - fn: 691.0000 - accuracy: 0.8905 - precision: 0.8998 - recall: 0.8797 - auc: 0.9786 - val_loss: 0.4133 - val_tp: 516.0000 - val_fp: 113.0000 - val_tn: 1165.0000 - val_fn: 123.0000 - val_accuracy: 0.8185 - val_precision: 0.8203 - val_recall: 0.8075 - val_auc: 0.9557\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.2844 - tp: 5021.0000 - fp: 598.0000 - tn: 10894.0000 - fn: 725.0000 - accuracy: 0.8832 - precision: 0.8936 - recall: 0.8738 - auc: 0.9774 - val_loss: 0.3689 - val_tp: 558.0000 - val_fp: 81.0000 - val_tn: 1197.0000 - val_fn: 81.0000 - val_accuracy: 0.8732 - val_precision: 0.8732 - val_recall: 0.8732 - val_auc: 0.9679\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.2651 - tp: 5074.0000 - fp: 550.0000 - tn: 10942.0000 - fn: 672.0000 - accuracy: 0.8937 - precision: 0.9022 - recall: 0.8830 - auc: 0.9804 - val_loss: 0.3062 - val_tp: 576.0000 - val_fp: 56.0000 - val_tn: 1222.0000 - val_fn: 63.0000 - val_accuracy: 0.9045 - val_precision: 0.9114 - val_recall: 0.9014 - val_auc: 0.9776\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.2610 - tp: 5098.0000 - fp: 527.0000 - tn: 10965.0000 - fn: 648.0000 - accuracy: 0.8980 - precision: 0.9063 - recall: 0.8872 - auc: 0.9808 - val_loss: 0.3464 - val_tp: 559.0000 - val_fp: 76.0000 - val_tn: 1202.0000 - val_fn: 80.0000 - val_accuracy: 0.8764 - val_precision: 0.8803 - val_recall: 0.8748 - val_auc: 0.9714\n",
            "============================================\n",
            "TRAINING IndoBert : , 4\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.7560 - tp: 3938.0000 - fp: 1250.0000 - tn: 10242.0000 - fn: 1808.0000 - accuracy: 0.7301 - precision: 0.7591 - recall: 0.6853 - auc: 0.8831WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 38s 287ms/step - loss: 0.7560 - tp: 3938.0000 - fp: 1250.0000 - tn: 10242.0000 - fn: 1808.0000 - accuracy: 0.7301 - precision: 0.7591 - recall: 0.6853 - auc: 0.8831 - val_loss: 0.3165 - val_tp: 547.0000 - val_fp: 51.0000 - val_tn: 1227.0000 - val_fn: 92.0000 - val_accuracy: 0.8811 - val_precision: 0.9147 - val_recall: 0.8560 - val_auc: 0.9789\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.4042 - tp: 4624.0000 - fp: 804.0000 - tn: 10688.0000 - fn: 1122.0000 - accuracy: 0.8319 - precision: 0.8519 - recall: 0.8047 - auc: 0.9551 - val_loss: 0.3444 - val_tp: 539.0000 - val_fp: 53.0000 - val_tn: 1225.0000 - val_fn: 100.0000 - val_accuracy: 0.8764 - val_precision: 0.9105 - val_recall: 0.8435 - val_auc: 0.9758\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.3613 - tp: 4744.0000 - fp: 707.0000 - tn: 10785.0000 - fn: 1002.0000 - accuracy: 0.8531 - precision: 0.8703 - recall: 0.8256 - auc: 0.9646 - val_loss: 0.2636 - val_tp: 571.0000 - val_fp: 52.0000 - val_tn: 1226.0000 - val_fn: 68.0000 - val_accuracy: 0.9061 - val_precision: 0.9165 - val_recall: 0.8936 - val_auc: 0.9820\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.3142 - tp: 4927.0000 - fp: 598.0000 - tn: 10894.0000 - fn: 819.0000 - accuracy: 0.8756 - precision: 0.8918 - recall: 0.8575 - auc: 0.9733 - val_loss: 0.2773 - val_tp: 565.0000 - val_fp: 64.0000 - val_tn: 1214.0000 - val_fn: 74.0000 - val_accuracy: 0.8920 - val_precision: 0.8983 - val_recall: 0.8842 - val_auc: 0.9774\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.2928 - tp: 4976.0000 - fp: 581.0000 - tn: 10911.0000 - fn: 770.0000 - accuracy: 0.8818 - precision: 0.8954 - recall: 0.8660 - auc: 0.9766 - val_loss: 0.2801 - val_tp: 563.0000 - val_fp: 69.0000 - val_tn: 1209.0000 - val_fn: 76.0000 - val_accuracy: 0.8858 - val_precision: 0.8908 - val_recall: 0.8811 - val_auc: 0.9780\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.2664 - tp: 5063.0000 - fp: 549.0000 - tn: 10943.0000 - fn: 683.0000 - accuracy: 0.8924 - precision: 0.9022 - recall: 0.8811 - auc: 0.9801 - val_loss: 0.2428 - val_tp: 572.0000 - val_fp: 54.0000 - val_tn: 1224.0000 - val_fn: 67.0000 - val_accuracy: 0.9045 - val_precision: 0.9137 - val_recall: 0.8951 - val_auc: 0.9831\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.2414 - tp: 5142.0000 - fp: 487.0000 - tn: 11005.0000 - fn: 604.0000 - accuracy: 0.9062 - precision: 0.9135 - recall: 0.8949 - auc: 0.9838 - val_loss: 0.2452 - val_tp: 578.0000 - val_fp: 54.0000 - val_tn: 1224.0000 - val_fn: 61.0000 - val_accuracy: 0.9092 - val_precision: 0.9146 - val_recall: 0.9045 - val_auc: 0.9821\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.2321 - tp: 5194.0000 - fp: 436.0000 - tn: 11056.0000 - fn: 552.0000 - accuracy: 0.9140 - precision: 0.9226 - recall: 0.9039 - auc: 0.9849 - val_loss: 0.3118 - val_tp: 567.0000 - val_fp: 68.0000 - val_tn: 1210.0000 - val_fn: 72.0000 - val_accuracy: 0.8905 - val_precision: 0.8929 - val_recall: 0.8873 - val_auc: 0.9746\n",
            "============================================\n",
            "TRAINING IndoBert : , 5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.9036 - tp: 3733.0000 - fp: 1427.0000 - tn: 10065.0000 - fn: 2013.0000 - accuracy: 0.6909 - precision: 0.7234 - recall: 0.6497 - auc: 0.8526WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 38s 291ms/step - loss: 0.9036 - tp: 3733.0000 - fp: 1427.0000 - tn: 10065.0000 - fn: 2013.0000 - accuracy: 0.6909 - precision: 0.7234 - recall: 0.6497 - auc: 0.8526 - val_loss: 0.3973 - val_tp: 541.0000 - val_fp: 77.0000 - val_tn: 1201.0000 - val_fn: 98.0000 - val_accuracy: 0.8623 - val_precision: 0.8754 - val_recall: 0.8466 - val_auc: 0.9661\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.4188 - tp: 4565.0000 - fp: 863.0000 - tn: 10629.0000 - fn: 1181.0000 - accuracy: 0.8207 - precision: 0.8410 - recall: 0.7945 - auc: 0.9515 - val_loss: 0.3785 - val_tp: 539.0000 - val_fp: 89.0000 - val_tn: 1189.0000 - val_fn: 100.0000 - val_accuracy: 0.8513 - val_precision: 0.8583 - val_recall: 0.8435 - val_auc: 0.9624\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.3535 - tp: 4790.0000 - fp: 713.0000 - tn: 10779.0000 - fn: 956.0000 - accuracy: 0.8535 - precision: 0.8704 - recall: 0.8336 - auc: 0.9656 - val_loss: 0.3185 - val_tp: 553.0000 - val_fp: 70.0000 - val_tn: 1208.0000 - val_fn: 86.0000 - val_accuracy: 0.8826 - val_precision: 0.8876 - val_recall: 0.8654 - val_auc: 0.9745\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.3272 - tp: 4908.0000 - fp: 668.0000 - tn: 10824.0000 - fn: 838.0000 - accuracy: 0.8665 - precision: 0.8802 - recall: 0.8542 - auc: 0.9703 - val_loss: 0.3271 - val_tp: 558.0000 - val_fp: 73.0000 - val_tn: 1205.0000 - val_fn: 81.0000 - val_accuracy: 0.8811 - val_precision: 0.8843 - val_recall: 0.8732 - val_auc: 0.9733\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.2834 - tp: 4983.0000 - fp: 593.0000 - tn: 10899.0000 - fn: 763.0000 - accuracy: 0.8815 - precision: 0.8937 - recall: 0.8672 - auc: 0.9774 - val_loss: 0.3762 - val_tp: 536.0000 - val_fp: 96.0000 - val_tn: 1182.0000 - val_fn: 103.0000 - val_accuracy: 0.8388 - val_precision: 0.8481 - val_recall: 0.8388 - val_auc: 0.9618\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.2614 - tp: 5113.0000 - fp: 519.0000 - tn: 10973.0000 - fn: 633.0000 - accuracy: 0.8970 - precision: 0.9078 - recall: 0.8898 - auc: 0.9810 - val_loss: 0.3529 - val_tp: 553.0000 - val_fp: 78.0000 - val_tn: 1200.0000 - val_fn: 86.0000 - val_accuracy: 0.8701 - val_precision: 0.8764 - val_recall: 0.8654 - val_auc: 0.9685\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.2431 - tp: 5142.0000 - fp: 486.0000 - tn: 11006.0000 - fn: 604.0000 - accuracy: 0.9046 - precision: 0.9136 - recall: 0.8949 - auc: 0.9833 - val_loss: 0.3502 - val_tp: 548.0000 - val_fp: 87.0000 - val_tn: 1191.0000 - val_fn: 91.0000 - val_accuracy: 0.8607 - val_precision: 0.8630 - val_recall: 0.8576 - val_auc: 0.9676\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.2312 - tp: 5151.0000 - fp: 493.0000 - tn: 10999.0000 - fn: 595.0000 - accuracy: 0.9050 - precision: 0.9127 - recall: 0.8964 - auc: 0.9847 - val_loss: 0.3272 - val_tp: 562.0000 - val_fp: 74.0000 - val_tn: 1204.0000 - val_fn: 77.0000 - val_accuracy: 0.8826 - val_precision: 0.8836 - val_recall: 0.8795 - val_auc: 0.9732\n",
            "============================================\n",
            "TRAINING Roberta : , 6\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8132 - tp: 3736.0000 - fp: 1563.0000 - tn: 9929.0000 - fn: 2010.0000 - accuracy: 0.6887 - precision: 0.7050 - recall: 0.6502 - auc: 0.8565WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 39s 297ms/step - loss: 0.8132 - tp: 3736.0000 - fp: 1563.0000 - tn: 9929.0000 - fn: 2010.0000 - accuracy: 0.6887 - precision: 0.7050 - recall: 0.6502 - auc: 0.8565 - val_loss: 0.5294 - val_tp: 492.0000 - val_fp: 144.0000 - val_tn: 1134.0000 - val_fn: 147.0000 - val_accuracy: 0.7715 - val_precision: 0.7736 - val_recall: 0.7700 - val_auc: 0.9313\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 261ms/step - loss: 0.4943 - tp: 4315.0000 - fp: 1080.0000 - tn: 10412.0000 - fn: 1431.0000 - accuracy: 0.7781 - precision: 0.7998 - recall: 0.7510 - auc: 0.9310 - val_loss: 0.4931 - val_tp: 502.0000 - val_fp: 130.0000 - val_tn: 1148.0000 - val_fn: 137.0000 - val_accuracy: 0.7887 - val_precision: 0.7943 - val_recall: 0.7856 - val_auc: 0.9429\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.4219 - tp: 4562.0000 - fp: 897.0000 - tn: 10595.0000 - fn: 1184.0000 - accuracy: 0.8197 - precision: 0.8357 - recall: 0.7939 - auc: 0.9504 - val_loss: 0.4484 - val_tp: 508.0000 - val_fp: 124.0000 - val_tn: 1154.0000 - val_fn: 131.0000 - val_accuracy: 0.7997 - val_precision: 0.8038 - val_recall: 0.7950 - val_auc: 0.9505\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.3800 - tp: 4688.0000 - fp: 838.0000 - tn: 10654.0000 - fn: 1058.0000 - accuracy: 0.8362 - precision: 0.8484 - recall: 0.8159 - auc: 0.9596 - val_loss: 0.4749 - val_tp: 510.0000 - val_fp: 114.0000 - val_tn: 1164.0000 - val_fn: 129.0000 - val_accuracy: 0.8028 - val_precision: 0.8173 - val_recall: 0.7981 - val_auc: 0.9488\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.3448 - tp: 4789.0000 - fp: 751.0000 - tn: 10741.0000 - fn: 957.0000 - accuracy: 0.8498 - precision: 0.8644 - recall: 0.8334 - auc: 0.9661 - val_loss: 0.4328 - val_tp: 521.0000 - val_fp: 115.0000 - val_tn: 1163.0000 - val_fn: 118.0000 - val_accuracy: 0.8185 - val_precision: 0.8192 - val_recall: 0.8153 - val_auc: 0.9555\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.3138 - tp: 4910.0000 - fp: 693.0000 - tn: 10799.0000 - fn: 836.0000 - accuracy: 0.8681 - precision: 0.8763 - recall: 0.8545 - auc: 0.9717 - val_loss: 0.3972 - val_tp: 535.0000 - val_fp: 99.0000 - val_tn: 1179.0000 - val_fn: 104.0000 - val_accuracy: 0.8404 - val_precision: 0.8438 - val_recall: 0.8372 - val_auc: 0.9581\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.2924 - tp: 4977.0000 - fp: 621.0000 - tn: 10871.0000 - fn: 769.0000 - accuracy: 0.8780 - precision: 0.8891 - recall: 0.8662 - auc: 0.9758 - val_loss: 0.4275 - val_tp: 532.0000 - val_fp: 104.0000 - val_tn: 1174.0000 - val_fn: 107.0000 - val_accuracy: 0.8326 - val_precision: 0.8365 - val_recall: 0.8326 - val_auc: 0.9576\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.2725 - tp: 5022.0000 - fp: 605.0000 - tn: 10887.0000 - fn: 724.0000 - accuracy: 0.8837 - precision: 0.8925 - recall: 0.8740 - auc: 0.9788 - val_loss: 0.4572 - val_tp: 530.0000 - val_fp: 101.0000 - val_tn: 1177.0000 - val_fn: 109.0000 - val_accuracy: 0.8326 - val_precision: 0.8399 - val_recall: 0.8294 - val_auc: 0.9562\n",
            "============================================\n",
            "TRAINING Roberta : , 7\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8271 - tp: 3551.0000 - fp: 1473.0000 - tn: 10019.0000 - fn: 2195.0000 - accuracy: 0.6726 - precision: 0.7068 - recall: 0.6180 - auc: 0.8473WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 39s 295ms/step - loss: 0.8271 - tp: 3551.0000 - fp: 1473.0000 - tn: 10019.0000 - fn: 2195.0000 - accuracy: 0.6726 - precision: 0.7068 - recall: 0.6180 - auc: 0.8473 - val_loss: 0.5250 - val_tp: 491.0000 - val_fp: 140.0000 - val_tn: 1138.0000 - val_fn: 148.0000 - val_accuracy: 0.7746 - val_precision: 0.7781 - val_recall: 0.7684 - val_auc: 0.9278\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 261ms/step - loss: 0.4857 - tp: 4297.0000 - fp: 1047.0000 - tn: 10445.0000 - fn: 1449.0000 - accuracy: 0.7835 - precision: 0.8041 - recall: 0.7478 - auc: 0.9328 - val_loss: 0.4732 - val_tp: 496.0000 - val_fp: 139.0000 - val_tn: 1139.0000 - val_fn: 143.0000 - val_accuracy: 0.7778 - val_precision: 0.7811 - val_recall: 0.7762 - val_auc: 0.9457\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.4357 - tp: 4480.0000 - fp: 961.0000 - tn: 10531.0000 - fn: 1266.0000 - accuracy: 0.8054 - precision: 0.8234 - recall: 0.7797 - auc: 0.9466 - val_loss: 0.3817 - val_tp: 525.0000 - val_fp: 108.0000 - val_tn: 1170.0000 - val_fn: 114.0000 - val_accuracy: 0.8279 - val_precision: 0.8294 - val_recall: 0.8216 - val_auc: 0.9576\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.3840 - tp: 4648.0000 - fp: 834.0000 - tn: 10658.0000 - fn: 1098.0000 - accuracy: 0.8305 - precision: 0.8479 - recall: 0.8089 - auc: 0.9582 - val_loss: 0.4754 - val_tp: 503.0000 - val_fp: 129.0000 - val_tn: 1149.0000 - val_fn: 136.0000 - val_accuracy: 0.7950 - val_precision: 0.7959 - val_recall: 0.7872 - val_auc: 0.9500\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.3628 - tp: 4759.0000 - fp: 776.0000 - tn: 10716.0000 - fn: 987.0000 - accuracy: 0.8451 - precision: 0.8598 - recall: 0.8282 - auc: 0.9633 - val_loss: 0.4829 - val_tp: 501.0000 - val_fp: 133.0000 - val_tn: 1145.0000 - val_fn: 138.0000 - val_accuracy: 0.7887 - val_precision: 0.7902 - val_recall: 0.7840 - val_auc: 0.9500\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.3302 - tp: 4827.0000 - fp: 726.0000 - tn: 10766.0000 - fn: 919.0000 - accuracy: 0.8566 - precision: 0.8693 - recall: 0.8401 - auc: 0.9693 - val_loss: 0.4660 - val_tp: 514.0000 - val_fp: 120.0000 - val_tn: 1158.0000 - val_fn: 125.0000 - val_accuracy: 0.8059 - val_precision: 0.8107 - val_recall: 0.8044 - val_auc: 0.9545\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.3146 - tp: 4918.0000 - fp: 665.0000 - tn: 10827.0000 - fn: 828.0000 - accuracy: 0.8690 - precision: 0.8809 - recall: 0.8559 - auc: 0.9720 - val_loss: 0.4206 - val_tp: 510.0000 - val_fp: 114.0000 - val_tn: 1164.0000 - val_fn: 129.0000 - val_accuracy: 0.8106 - val_precision: 0.8173 - val_recall: 0.7981 - val_auc: 0.9566\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.3024 - tp: 4938.0000 - fp: 670.0000 - tn: 10822.0000 - fn: 808.0000 - accuracy: 0.8710 - precision: 0.8805 - recall: 0.8594 - auc: 0.9739 - val_loss: 0.3827 - val_tp: 540.0000 - val_fp: 97.0000 - val_tn: 1181.0000 - val_fn: 99.0000 - val_accuracy: 0.8451 - val_precision: 0.8477 - val_recall: 0.8451 - val_auc: 0.9612\n",
            "============================================\n",
            "TRAINING Roberta : , 8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8892 - tp: 3540.0000 - fp: 1482.0000 - tn: 10010.0000 - fn: 2206.0000 - accuracy: 0.6740 - precision: 0.7049 - recall: 0.6161 - auc: 0.8401WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 39s 294ms/step - loss: 0.8892 - tp: 3540.0000 - fp: 1482.0000 - tn: 10010.0000 - fn: 2206.0000 - accuracy: 0.6740 - precision: 0.7049 - recall: 0.6161 - auc: 0.8401 - val_loss: 0.4453 - val_tp: 509.0000 - val_fp: 122.0000 - val_tn: 1156.0000 - val_fn: 130.0000 - val_accuracy: 0.8028 - val_precision: 0.8067 - val_recall: 0.7966 - val_auc: 0.9439\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 24s 262ms/step - loss: 0.4748 - tp: 4365.0000 - fp: 993.0000 - tn: 10499.0000 - fn: 1381.0000 - accuracy: 0.7931 - precision: 0.8147 - recall: 0.7597 - auc: 0.9372 - val_loss: 0.4407 - val_tp: 517.0000 - val_fp: 120.0000 - val_tn: 1158.0000 - val_fn: 122.0000 - val_accuracy: 0.8091 - val_precision: 0.8116 - val_recall: 0.8091 - val_auc: 0.9480\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.4308 - tp: 4524.0000 - fp: 896.0000 - tn: 10596.0000 - fn: 1222.0000 - accuracy: 0.8167 - precision: 0.8347 - recall: 0.7873 - auc: 0.9480 - val_loss: 0.3896 - val_tp: 531.0000 - val_fp: 102.0000 - val_tn: 1176.0000 - val_fn: 108.0000 - val_accuracy: 0.8357 - val_precision: 0.8389 - val_recall: 0.8310 - val_auc: 0.9567\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.3789 - tp: 4710.0000 - fp: 806.0000 - tn: 10686.0000 - fn: 1036.0000 - accuracy: 0.8385 - precision: 0.8539 - recall: 0.8197 - auc: 0.9599 - val_loss: 0.4006 - val_tp: 519.0000 - val_fp: 112.0000 - val_tn: 1166.0000 - val_fn: 120.0000 - val_accuracy: 0.8169 - val_precision: 0.8225 - val_recall: 0.8122 - val_auc: 0.9549\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.3752 - tp: 4723.0000 - fp: 794.0000 - tn: 10698.0000 - fn: 1023.0000 - accuracy: 0.8423 - precision: 0.8561 - recall: 0.8220 - auc: 0.9604 - val_loss: 0.3982 - val_tp: 526.0000 - val_fp: 108.0000 - val_tn: 1170.0000 - val_fn: 113.0000 - val_accuracy: 0.8263 - val_precision: 0.8297 - val_recall: 0.8232 - val_auc: 0.9552\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.3363 - tp: 4890.0000 - fp: 691.0000 - tn: 10801.0000 - fn: 856.0000 - accuracy: 0.8649 - precision: 0.8762 - recall: 0.8510 - auc: 0.9683 - val_loss: 0.3627 - val_tp: 544.0000 - val_fp: 92.0000 - val_tn: 1186.0000 - val_fn: 95.0000 - val_accuracy: 0.8513 - val_precision: 0.8553 - val_recall: 0.8513 - val_auc: 0.9654\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.3364 - tp: 4845.0000 - fp: 731.0000 - tn: 10761.0000 - fn: 901.0000 - accuracy: 0.8566 - precision: 0.8689 - recall: 0.8432 - auc: 0.9680 - val_loss: 0.3624 - val_tp: 541.0000 - val_fp: 88.0000 - val_tn: 1190.0000 - val_fn: 98.0000 - val_accuracy: 0.8545 - val_precision: 0.8601 - val_recall: 0.8466 - val_auc: 0.9637\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.3192 - tp: 4885.0000 - fp: 700.0000 - tn: 10792.0000 - fn: 861.0000 - accuracy: 0.8632 - precision: 0.8747 - recall: 0.8502 - auc: 0.9714 - val_loss: 0.3596 - val_tp: 542.0000 - val_fp: 87.0000 - val_tn: 1191.0000 - val_fn: 97.0000 - val_accuracy: 0.8560 - val_precision: 0.8617 - val_recall: 0.8482 - val_auc: 0.9649\n",
            "============================================\n",
            "TRAINING Roberta : , 9\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8826 - tp: 3630.0000 - fp: 1552.0000 - tn: 9940.0000 - fn: 2116.0000 - accuracy: 0.6759 - precision: 0.7005 - recall: 0.6317 - auc: 0.8386WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 40s 291ms/step - loss: 0.8826 - tp: 3630.0000 - fp: 1552.0000 - tn: 9940.0000 - fn: 2116.0000 - accuracy: 0.6759 - precision: 0.7005 - recall: 0.6317 - auc: 0.8386 - val_loss: 0.4746 - val_tp: 485.0000 - val_fp: 142.0000 - val_tn: 1136.0000 - val_fn: 154.0000 - val_accuracy: 0.7684 - val_precision: 0.7735 - val_recall: 0.7590 - val_auc: 0.9380\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.4783 - tp: 4378.0000 - fp: 1026.0000 - tn: 10466.0000 - fn: 1368.0000 - accuracy: 0.7920 - precision: 0.8101 - recall: 0.7619 - auc: 0.9360 - val_loss: 0.4164 - val_tp: 512.0000 - val_fp: 109.0000 - val_tn: 1169.0000 - val_fn: 127.0000 - val_accuracy: 0.8185 - val_precision: 0.8245 - val_recall: 0.8013 - val_auc: 0.9511\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.4106 - tp: 4616.0000 - fp: 877.0000 - tn: 10615.0000 - fn: 1130.0000 - accuracy: 0.8234 - precision: 0.8403 - recall: 0.8033 - auc: 0.9530 - val_loss: 0.3745 - val_tp: 538.0000 - val_fp: 91.0000 - val_tn: 1187.0000 - val_fn: 101.0000 - val_accuracy: 0.8529 - val_precision: 0.8553 - val_recall: 0.8419 - val_auc: 0.9618\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.3682 - tp: 4695.0000 - fp: 792.0000 - tn: 10700.0000 - fn: 1051.0000 - accuracy: 0.8364 - precision: 0.8557 - recall: 0.8171 - auc: 0.9618 - val_loss: 0.3637 - val_tp: 543.0000 - val_fp: 86.0000 - val_tn: 1192.0000 - val_fn: 96.0000 - val_accuracy: 0.8576 - val_precision: 0.8633 - val_recall: 0.8498 - val_auc: 0.9627\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.3394 - tp: 4791.0000 - fp: 777.0000 - tn: 10715.0000 - fn: 955.0000 - accuracy: 0.8470 - precision: 0.8605 - recall: 0.8338 - auc: 0.9674 - val_loss: 0.3817 - val_tp: 526.0000 - val_fp: 98.0000 - val_tn: 1180.0000 - val_fn: 113.0000 - val_accuracy: 0.8310 - val_precision: 0.8429 - val_recall: 0.8232 - val_auc: 0.9595\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.3140 - tp: 4914.0000 - fp: 663.0000 - tn: 10829.0000 - fn: 832.0000 - accuracy: 0.8691 - precision: 0.8811 - recall: 0.8552 - auc: 0.9723 - val_loss: 0.3552 - val_tp: 541.0000 - val_fp: 93.0000 - val_tn: 1185.0000 - val_fn: 98.0000 - val_accuracy: 0.8482 - val_precision: 0.8533 - val_recall: 0.8466 - val_auc: 0.9633\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 24s 263ms/step - loss: 0.3060 - tp: 4939.0000 - fp: 680.0000 - tn: 10812.0000 - fn: 807.0000 - accuracy: 0.8698 - precision: 0.8790 - recall: 0.8596 - auc: 0.9734 - val_loss: 0.3735 - val_tp: 541.0000 - val_fp: 90.0000 - val_tn: 1188.0000 - val_fn: 98.0000 - val_accuracy: 0.8529 - val_precision: 0.8574 - val_recall: 0.8466 - val_auc: 0.9622\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.3035 - tp: 4922.0000 - fp: 670.0000 - tn: 10822.0000 - fn: 824.0000 - accuracy: 0.8698 - precision: 0.8802 - recall: 0.8566 - auc: 0.9738 - val_loss: 0.3893 - val_tp: 530.0000 - val_fp: 99.0000 - val_tn: 1179.0000 - val_fn: 109.0000 - val_accuracy: 0.8357 - val_precision: 0.8426 - val_recall: 0.8294 - val_auc: 0.9587\n",
            "============================================\n",
            "TRAINING Roberta : , 10\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.7480 - tp: 3756.0000 - fp: 1397.0000 - tn: 10095.0000 - fn: 1990.0000 - accuracy: 0.6986 - precision: 0.7289 - recall: 0.6537 - auc: 0.8638WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 40s 302ms/step - loss: 0.7480 - tp: 3756.0000 - fp: 1397.0000 - tn: 10095.0000 - fn: 1990.0000 - accuracy: 0.6986 - precision: 0.7289 - recall: 0.6537 - auc: 0.8638 - val_loss: 0.4451 - val_tp: 501.0000 - val_fp: 119.0000 - val_tn: 1159.0000 - val_fn: 138.0000 - val_accuracy: 0.7950 - val_precision: 0.8081 - val_recall: 0.7840 - val_auc: 0.9468\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.4573 - tp: 4460.0000 - fp: 953.0000 - tn: 10539.0000 - fn: 1286.0000 - accuracy: 0.8053 - precision: 0.8239 - recall: 0.7762 - auc: 0.9416 - val_loss: 0.3909 - val_tp: 519.0000 - val_fp: 70.0000 - val_tn: 1208.0000 - val_fn: 120.0000 - val_accuracy: 0.8498 - val_precision: 0.8812 - val_recall: 0.8122 - val_auc: 0.9632\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.4017 - tp: 4634.0000 - fp: 861.0000 - tn: 10631.0000 - fn: 1112.0000 - accuracy: 0.8267 - precision: 0.8433 - recall: 0.8065 - auc: 0.9544 - val_loss: 0.3736 - val_tp: 523.0000 - val_fp: 98.0000 - val_tn: 1180.0000 - val_fn: 116.0000 - val_accuracy: 0.8341 - val_precision: 0.8422 - val_recall: 0.8185 - val_auc: 0.9617\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.3650 - tp: 4766.0000 - fp: 768.0000 - tn: 10724.0000 - fn: 980.0000 - accuracy: 0.8482 - precision: 0.8612 - recall: 0.8294 - auc: 0.9628 - val_loss: 0.4044 - val_tp: 522.0000 - val_fp: 96.0000 - val_tn: 1182.0000 - val_fn: 117.0000 - val_accuracy: 0.8294 - val_precision: 0.8447 - val_recall: 0.8169 - val_auc: 0.9562\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.3304 - tp: 4860.0000 - fp: 693.0000 - tn: 10799.0000 - fn: 886.0000 - accuracy: 0.8620 - precision: 0.8752 - recall: 0.8458 - auc: 0.9696 - val_loss: 0.3907 - val_tp: 520.0000 - val_fp: 95.0000 - val_tn: 1183.0000 - val_fn: 119.0000 - val_accuracy: 0.8247 - val_precision: 0.8455 - val_recall: 0.8138 - val_auc: 0.9594\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 24s 265ms/step - loss: 0.3029 - tp: 4965.0000 - fp: 635.0000 - tn: 10857.0000 - fn: 781.0000 - accuracy: 0.8775 - precision: 0.8866 - recall: 0.8641 - auc: 0.9743 - val_loss: 0.4146 - val_tp: 510.0000 - val_fp: 102.0000 - val_tn: 1176.0000 - val_fn: 129.0000 - val_accuracy: 0.8169 - val_precision: 0.8333 - val_recall: 0.7981 - val_auc: 0.9547\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.3019 - tp: 4955.0000 - fp: 643.0000 - tn: 10849.0000 - fn: 791.0000 - accuracy: 0.8728 - precision: 0.8851 - recall: 0.8623 - auc: 0.9743 - val_loss: 0.3698 - val_tp: 541.0000 - val_fp: 85.0000 - val_tn: 1193.0000 - val_fn: 98.0000 - val_accuracy: 0.8576 - val_precision: 0.8642 - val_recall: 0.8466 - val_auc: 0.9648\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 24s 264ms/step - loss: 0.2808 - tp: 5007.0000 - fp: 623.0000 - tn: 10869.0000 - fn: 739.0000 - accuracy: 0.8817 - precision: 0.8893 - recall: 0.8714 - auc: 0.9776 - val_loss: 0.3824 - val_tp: 538.0000 - val_fp: 97.0000 - val_tn: 1181.0000 - val_fn: 101.0000 - val_accuracy: 0.8435 - val_precision: 0.8472 - val_recall: 0.8419 - val_auc: 0.9620\n",
            "============================================\n",
            "TRAINING Bert : , 11\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 1.1106 - tp: 2845.0000 - fp: 1666.0000 - tn: 9826.0000 - fn: 2901.0000 - accuracy: 0.5919 - precision: 0.6307 - recall: 0.4951 - auc: 0.7539WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 39s 294ms/step - loss: 1.1106 - tp: 2845.0000 - fp: 1666.0000 - tn: 9826.0000 - fn: 2901.0000 - accuracy: 0.5919 - precision: 0.6307 - recall: 0.4951 - auc: 0.7539 - val_loss: 0.7420 - val_tp: 362.0000 - val_fp: 136.0000 - val_tn: 1142.0000 - val_fn: 277.0000 - val_accuracy: 0.6526 - val_precision: 0.7269 - val_recall: 0.5665 - val_auc: 0.8450\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 261ms/step - loss: 0.7278 - tp: 3419.0000 - fp: 1260.0000 - tn: 10232.0000 - fn: 2327.0000 - accuracy: 0.6803 - precision: 0.7307 - recall: 0.5950 - auc: 0.8522 - val_loss: 0.7154 - val_tp: 388.0000 - val_fp: 135.0000 - val_tn: 1143.0000 - val_fn: 251.0000 - val_accuracy: 0.6823 - val_precision: 0.7419 - val_recall: 0.6072 - val_auc: 0.8572\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.6770 - tp: 3566.0000 - fp: 1153.0000 - tn: 10339.0000 - fn: 2180.0000 - accuracy: 0.7026 - precision: 0.7557 - recall: 0.6206 - auc: 0.8722 - val_loss: 0.6463 - val_tp: 403.0000 - val_fp: 134.0000 - val_tn: 1144.0000 - val_fn: 236.0000 - val_accuracy: 0.7042 - val_precision: 0.7505 - val_recall: 0.6307 - val_auc: 0.8845\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.6297 - tp: 3643.0000 - fp: 1039.0000 - tn: 10453.0000 - fn: 2103.0000 - accuracy: 0.7203 - precision: 0.7781 - recall: 0.6340 - auc: 0.8905 - val_loss: 0.6199 - val_tp: 392.0000 - val_fp: 105.0000 - val_tn: 1173.0000 - val_fn: 247.0000 - val_accuracy: 0.7308 - val_precision: 0.7887 - val_recall: 0.6135 - val_auc: 0.8965\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.5910 - tp: 3832.0000 - fp: 981.0000 - tn: 10511.0000 - fn: 1914.0000 - accuracy: 0.7431 - precision: 0.7962 - recall: 0.6669 - auc: 0.9045 - val_loss: 0.6291 - val_tp: 401.0000 - val_fp: 114.0000 - val_tn: 1164.0000 - val_fn: 238.0000 - val_accuracy: 0.7246 - val_precision: 0.7786 - val_recall: 0.6275 - val_auc: 0.8939\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.5769 - tp: 3814.0000 - fp: 977.0000 - tn: 10515.0000 - fn: 1932.0000 - accuracy: 0.7456 - precision: 0.7961 - recall: 0.6638 - auc: 0.9081 - val_loss: 0.5992 - val_tp: 438.0000 - val_fp: 138.0000 - val_tn: 1140.0000 - val_fn: 201.0000 - val_accuracy: 0.7355 - val_precision: 0.7604 - val_recall: 0.6854 - val_auc: 0.9029\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.5378 - tp: 3947.0000 - fp: 945.0000 - tn: 10547.0000 - fn: 1799.0000 - accuracy: 0.7586 - precision: 0.8068 - recall: 0.6869 - auc: 0.9199 - val_loss: 0.6346 - val_tp: 417.0000 - val_fp: 113.0000 - val_tn: 1165.0000 - val_fn: 222.0000 - val_accuracy: 0.7261 - val_precision: 0.7868 - val_recall: 0.6526 - val_auc: 0.8915\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.5116 - tp: 4080.0000 - fp: 901.0000 - tn: 10591.0000 - fn: 1666.0000 - accuracy: 0.7720 - precision: 0.8191 - recall: 0.7101 - auc: 0.9275 - val_loss: 0.5834 - val_tp: 430.0000 - val_fp: 114.0000 - val_tn: 1164.0000 - val_fn: 209.0000 - val_accuracy: 0.7527 - val_precision: 0.7904 - val_recall: 0.6729 - val_auc: 0.9096\n",
            "============================================\n",
            "TRAINING Bert : , 12\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 1.1983 - tp: 2967.0000 - fp: 1799.0000 - tn: 9693.0000 - fn: 2779.0000 - accuracy: 0.5903 - precision: 0.6225 - recall: 0.5164 - auc: 0.7528WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 39s 293ms/step - loss: 1.1983 - tp: 2967.0000 - fp: 1799.0000 - tn: 9693.0000 - fn: 2779.0000 - accuracy: 0.5903 - precision: 0.6225 - recall: 0.5164 - auc: 0.7528 - val_loss: 0.6657 - val_tp: 419.0000 - val_fp: 167.0000 - val_tn: 1111.0000 - val_fn: 220.0000 - val_accuracy: 0.6917 - val_precision: 0.7150 - val_recall: 0.6557 - val_auc: 0.8776\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.6996 - tp: 3499.0000 - fp: 1216.0000 - tn: 10276.0000 - fn: 2247.0000 - accuracy: 0.6876 - precision: 0.7421 - recall: 0.6089 - auc: 0.8636 - val_loss: 0.6204 - val_tp: 412.0000 - val_fp: 123.0000 - val_tn: 1155.0000 - val_fn: 227.0000 - val_accuracy: 0.7167 - val_precision: 0.7701 - val_recall: 0.6448 - val_auc: 0.8932\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.6464 - tp: 3691.0000 - fp: 1211.0000 - tn: 10281.0000 - fn: 2055.0000 - accuracy: 0.7118 - precision: 0.7530 - recall: 0.6424 - auc: 0.8831 - val_loss: 0.5940 - val_tp: 439.0000 - val_fp: 143.0000 - val_tn: 1135.0000 - val_fn: 200.0000 - val_accuracy: 0.7277 - val_precision: 0.7543 - val_recall: 0.6870 - val_auc: 0.9025\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.6064 - tp: 3847.0000 - fp: 1149.0000 - tn: 10343.0000 - fn: 1899.0000 - accuracy: 0.7296 - precision: 0.7700 - recall: 0.6695 - auc: 0.8974 - val_loss: 0.5662 - val_tp: 446.0000 - val_fp: 122.0000 - val_tn: 1156.0000 - val_fn: 193.0000 - val_accuracy: 0.7480 - val_precision: 0.7852 - val_recall: 0.6980 - val_auc: 0.9130\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.5686 - tp: 3964.0000 - fp: 1044.0000 - tn: 10448.0000 - fn: 1782.0000 - accuracy: 0.7501 - precision: 0.7915 - recall: 0.6899 - auc: 0.9101 - val_loss: 0.5694 - val_tp: 431.0000 - val_fp: 103.0000 - val_tn: 1175.0000 - val_fn: 208.0000 - val_accuracy: 0.7512 - val_precision: 0.8071 - val_recall: 0.6745 - val_auc: 0.9131\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.5378 - tp: 4074.0000 - fp: 998.0000 - tn: 10494.0000 - fn: 1672.0000 - accuracy: 0.7640 - precision: 0.8032 - recall: 0.7090 - auc: 0.9203 - val_loss: 0.5782 - val_tp: 453.0000 - val_fp: 136.0000 - val_tn: 1142.0000 - val_fn: 186.0000 - val_accuracy: 0.7246 - val_precision: 0.7691 - val_recall: 0.7089 - val_auc: 0.9106\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.5133 - tp: 4140.0000 - fp: 979.0000 - tn: 10513.0000 - fn: 1606.0000 - accuracy: 0.7722 - precision: 0.8088 - recall: 0.7205 - auc: 0.9270 - val_loss: 0.6139 - val_tp: 456.0000 - val_fp: 154.0000 - val_tn: 1124.0000 - val_fn: 183.0000 - val_accuracy: 0.7340 - val_precision: 0.7475 - val_recall: 0.7136 - val_auc: 0.9105\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 24s 263ms/step - loss: 0.5022 - tp: 4174.0000 - fp: 948.0000 - tn: 10544.0000 - fn: 1572.0000 - accuracy: 0.7769 - precision: 0.8149 - recall: 0.7264 - auc: 0.9300 - val_loss: 0.6135 - val_tp: 455.0000 - val_fp: 137.0000 - val_tn: 1141.0000 - val_fn: 184.0000 - val_accuracy: 0.7480 - val_precision: 0.7686 - val_recall: 0.7121 - val_auc: 0.9069\n",
            "============================================\n",
            "TRAINING Bert : , 13\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 1.0738 - tp: 2869.0000 - fp: 1751.0000 - tn: 9741.0000 - fn: 2877.0000 - accuracy: 0.5905 - precision: 0.6210 - recall: 0.4993 - auc: 0.7519WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 38s 297ms/step - loss: 1.0738 - tp: 2869.0000 - fp: 1751.0000 - tn: 9741.0000 - fn: 2877.0000 - accuracy: 0.5905 - precision: 0.6210 - recall: 0.4993 - auc: 0.7519 - val_loss: 0.7497 - val_tp: 415.0000 - val_fp: 195.0000 - val_tn: 1083.0000 - val_fn: 224.0000 - val_accuracy: 0.6651 - val_precision: 0.6803 - val_recall: 0.6495 - val_auc: 0.8492\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 24s 261ms/step - loss: 0.7124 - tp: 3514.0000 - fp: 1291.0000 - tn: 10201.0000 - fn: 2232.0000 - accuracy: 0.6892 - precision: 0.7313 - recall: 0.6116 - auc: 0.8576 - val_loss: 0.6784 - val_tp: 431.0000 - val_fp: 174.0000 - val_tn: 1104.0000 - val_fn: 208.0000 - val_accuracy: 0.6886 - val_precision: 0.7124 - val_recall: 0.6745 - val_auc: 0.8759\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 24s 264ms/step - loss: 0.6552 - tp: 3684.0000 - fp: 1170.0000 - tn: 10322.0000 - fn: 2062.0000 - accuracy: 0.7137 - precision: 0.7590 - recall: 0.6411 - auc: 0.8814 - val_loss: 0.7222 - val_tp: 441.0000 - val_fp: 184.0000 - val_tn: 1094.0000 - val_fn: 198.0000 - val_accuracy: 0.7011 - val_precision: 0.7056 - val_recall: 0.6901 - val_auc: 0.8788\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.6106 - tp: 3854.0000 - fp: 1100.0000 - tn: 10392.0000 - fn: 1892.0000 - accuracy: 0.7348 - precision: 0.7780 - recall: 0.6707 - auc: 0.8978 - val_loss: 0.6795 - val_tp: 443.0000 - val_fp: 169.0000 - val_tn: 1109.0000 - val_fn: 196.0000 - val_accuracy: 0.7058 - val_precision: 0.7239 - val_recall: 0.6933 - val_auc: 0.8834\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.5863 - tp: 3898.0000 - fp: 1105.0000 - tn: 10387.0000 - fn: 1848.0000 - accuracy: 0.7386 - precision: 0.7791 - recall: 0.6784 - auc: 0.9048 - val_loss: 0.6206 - val_tp: 449.0000 - val_fp: 171.0000 - val_tn: 1107.0000 - val_fn: 190.0000 - val_accuracy: 0.7167 - val_precision: 0.7242 - val_recall: 0.7027 - val_auc: 0.8990\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.5661 - tp: 3959.0000 - fp: 1050.0000 - tn: 10442.0000 - fn: 1787.0000 - accuracy: 0.7436 - precision: 0.7904 - recall: 0.6890 - auc: 0.9110 - val_loss: 0.7272 - val_tp: 434.0000 - val_fp: 186.0000 - val_tn: 1092.0000 - val_fn: 205.0000 - val_accuracy: 0.6933 - val_precision: 0.7000 - val_recall: 0.6792 - val_auc: 0.8827\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.5470 - tp: 4024.0000 - fp: 1015.0000 - tn: 10477.0000 - fn: 1722.0000 - accuracy: 0.7541 - precision: 0.7986 - recall: 0.7003 - auc: 0.9170 - val_loss: 0.6466 - val_tp: 449.0000 - val_fp: 173.0000 - val_tn: 1105.0000 - val_fn: 190.0000 - val_accuracy: 0.7167 - val_precision: 0.7219 - val_recall: 0.7027 - val_auc: 0.8968\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.5022 - tp: 4200.0000 - fp: 934.0000 - tn: 10558.0000 - fn: 1546.0000 - accuracy: 0.7804 - precision: 0.8181 - recall: 0.7309 - auc: 0.9305 - val_loss: 0.6407 - val_tp: 459.0000 - val_fp: 171.0000 - val_tn: 1107.0000 - val_fn: 180.0000 - val_accuracy: 0.7214 - val_precision: 0.7286 - val_recall: 0.7183 - val_auc: 0.9065\n",
            "============================================\n",
            "TRAINING Bert : , 14\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.9935 - tp: 2747.0000 - fp: 1503.0000 - tn: 9989.0000 - fn: 2999.0000 - accuracy: 0.5940 - precision: 0.6464 - recall: 0.4781 - auc: 0.7632WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 40s 290ms/step - loss: 0.9935 - tp: 2747.0000 - fp: 1503.0000 - tn: 9989.0000 - fn: 2999.0000 - accuracy: 0.5940 - precision: 0.6464 - recall: 0.4781 - auc: 0.7632 - val_loss: 0.7220 - val_tp: 433.0000 - val_fp: 170.0000 - val_tn: 1108.0000 - val_fn: 206.0000 - val_accuracy: 0.6980 - val_precision: 0.7181 - val_recall: 0.6776 - val_auc: 0.8568\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.7143 - tp: 3439.0000 - fp: 1263.0000 - tn: 10229.0000 - fn: 2307.0000 - accuracy: 0.6815 - precision: 0.7314 - recall: 0.5985 - auc: 0.8578 - val_loss: 0.7313 - val_tp: 412.0000 - val_fp: 146.0000 - val_tn: 1132.0000 - val_fn: 227.0000 - val_accuracy: 0.6839 - val_precision: 0.7384 - val_recall: 0.6448 - val_auc: 0.8564\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.6601 - tp: 3666.0000 - fp: 1227.0000 - tn: 10265.0000 - fn: 2080.0000 - accuracy: 0.7024 - precision: 0.7492 - recall: 0.6380 - auc: 0.8780 - val_loss: 0.6358 - val_tp: 433.0000 - val_fp: 138.0000 - val_tn: 1140.0000 - val_fn: 206.0000 - val_accuracy: 0.7183 - val_precision: 0.7583 - val_recall: 0.6776 - val_auc: 0.8919\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.6116 - tp: 3819.0000 - fp: 1164.0000 - tn: 10328.0000 - fn: 1927.0000 - accuracy: 0.7266 - precision: 0.7664 - recall: 0.6646 - auc: 0.8962 - val_loss: 0.6273 - val_tp: 449.0000 - val_fp: 153.0000 - val_tn: 1125.0000 - val_fn: 190.0000 - val_accuracy: 0.7199 - val_precision: 0.7458 - val_recall: 0.7027 - val_auc: 0.8953\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.5987 - tp: 3824.0000 - fp: 1111.0000 - tn: 10381.0000 - fn: 1922.0000 - accuracy: 0.7339 - precision: 0.7749 - recall: 0.6655 - auc: 0.9006 - val_loss: 0.6776 - val_tp: 399.0000 - val_fp: 113.0000 - val_tn: 1165.0000 - val_fn: 240.0000 - val_accuracy: 0.7152 - val_precision: 0.7793 - val_recall: 0.6244 - val_auc: 0.8821\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.5608 - tp: 3962.0000 - fp: 1007.0000 - tn: 10485.0000 - fn: 1784.0000 - accuracy: 0.7517 - precision: 0.7973 - recall: 0.6895 - auc: 0.9129 - val_loss: 0.6746 - val_tp: 411.0000 - val_fp: 121.0000 - val_tn: 1157.0000 - val_fn: 228.0000 - val_accuracy: 0.7246 - val_precision: 0.7726 - val_recall: 0.6432 - val_auc: 0.8858\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 250ms/step - loss: 0.5479 - tp: 4017.0000 - fp: 1031.0000 - tn: 10461.0000 - fn: 1729.0000 - accuracy: 0.7565 - precision: 0.7958 - recall: 0.6991 - auc: 0.9164 - val_loss: 0.6253 - val_tp: 447.0000 - val_fp: 140.0000 - val_tn: 1138.0000 - val_fn: 192.0000 - val_accuracy: 0.7277 - val_precision: 0.7615 - val_recall: 0.6995 - val_auc: 0.8976\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 22s 249ms/step - loss: 0.5240 - tp: 4112.0000 - fp: 1006.0000 - tn: 10486.0000 - fn: 1634.0000 - accuracy: 0.7710 - precision: 0.8034 - recall: 0.7156 - auc: 0.9235 - val_loss: 0.6326 - val_tp: 448.0000 - val_fp: 130.0000 - val_tn: 1148.0000 - val_fn: 191.0000 - val_accuracy: 0.7355 - val_precision: 0.7751 - val_recall: 0.7011 - val_auc: 0.9007\n",
            "============================================\n",
            "TRAINING Bert : , 15\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 1.0259 - tp: 2796.0000 - fp: 1603.0000 - tn: 9889.0000 - fn: 2950.0000 - accuracy: 0.5985 - precision: 0.6356 - recall: 0.4866 - auc: 0.7589WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 38s 290ms/step - loss: 1.0259 - tp: 2796.0000 - fp: 1603.0000 - tn: 9889.0000 - fn: 2950.0000 - accuracy: 0.5985 - precision: 0.6356 - recall: 0.4866 - auc: 0.7589 - val_loss: 0.6819 - val_tp: 398.0000 - val_fp: 130.0000 - val_tn: 1148.0000 - val_fn: 241.0000 - val_accuracy: 0.6995 - val_precision: 0.7538 - val_recall: 0.6228 - val_auc: 0.8725\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.7142 - tp: 3365.0000 - fp: 1189.0000 - tn: 10303.0000 - fn: 2381.0000 - accuracy: 0.6855 - precision: 0.7389 - recall: 0.5856 - auc: 0.8577 - val_loss: 0.6575 - val_tp: 419.0000 - val_fp: 162.0000 - val_tn: 1116.0000 - val_fn: 220.0000 - val_accuracy: 0.6886 - val_precision: 0.7212 - val_recall: 0.6557 - val_auc: 0.8778\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.6616 - tp: 3557.0000 - fp: 1067.0000 - tn: 10425.0000 - fn: 2189.0000 - accuracy: 0.7081 - precision: 0.7692 - recall: 0.6190 - auc: 0.8796 - val_loss: 0.6643 - val_tp: 431.0000 - val_fp: 171.0000 - val_tn: 1107.0000 - val_fn: 208.0000 - val_accuracy: 0.6995 - val_precision: 0.7159 - val_recall: 0.6745 - val_auc: 0.8808\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.6262 - tp: 3663.0000 - fp: 1068.0000 - tn: 10424.0000 - fn: 2083.0000 - accuracy: 0.7210 - precision: 0.7743 - recall: 0.6375 - auc: 0.8903 - val_loss: 0.6720 - val_tp: 422.0000 - val_fp: 162.0000 - val_tn: 1116.0000 - val_fn: 217.0000 - val_accuracy: 0.7011 - val_precision: 0.7226 - val_recall: 0.6604 - val_auc: 0.8775\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.5998 - tp: 3720.0000 - fp: 1037.0000 - tn: 10455.0000 - fn: 2026.0000 - accuracy: 0.7313 - precision: 0.7820 - recall: 0.6474 - auc: 0.8985 - val_loss: 0.6095 - val_tp: 398.0000 - val_fp: 98.0000 - val_tn: 1180.0000 - val_fn: 241.0000 - val_accuracy: 0.7308 - val_precision: 0.8024 - val_recall: 0.6228 - val_auc: 0.9007\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.5815 - tp: 3848.0000 - fp: 964.0000 - tn: 10528.0000 - fn: 1898.0000 - accuracy: 0.7421 - precision: 0.7997 - recall: 0.6697 - auc: 0.9071 - val_loss: 0.7001 - val_tp: 425.0000 - val_fp: 156.0000 - val_tn: 1122.0000 - val_fn: 214.0000 - val_accuracy: 0.6933 - val_precision: 0.7315 - val_recall: 0.6651 - val_auc: 0.8737\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.5610 - tp: 3863.0000 - fp: 970.0000 - tn: 10522.0000 - fn: 1883.0000 - accuracy: 0.7515 - precision: 0.7993 - recall: 0.6723 - auc: 0.9131 - val_loss: 0.6221 - val_tp: 447.0000 - val_fp: 156.0000 - val_tn: 1122.0000 - val_fn: 192.0000 - val_accuracy: 0.7246 - val_precision: 0.7413 - val_recall: 0.6995 - val_auc: 0.8976\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.5384 - tp: 4011.0000 - fp: 937.0000 - tn: 10555.0000 - fn: 1735.0000 - accuracy: 0.7626 - precision: 0.8106 - recall: 0.6981 - auc: 0.9196 - val_loss: 0.5714 - val_tp: 438.0000 - val_fp: 103.0000 - val_tn: 1175.0000 - val_fn: 201.0000 - val_accuracy: 0.7653 - val_precision: 0.8096 - val_recall: 0.6854 - val_auc: 0.9125\n",
            "============================================\n",
            "TRAINING GPT2 : , 16\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 1.0553 - tp: 3783.0000 - fp: 1506.0000 - tn: 9986.0000 - fn: 1963.0000 - accuracy: 0.6965 - precision: 0.7153 - recall: 0.6584 - auc: 0.8457WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 36s 271ms/step - loss: 1.0553 - tp: 3783.0000 - fp: 1506.0000 - tn: 9986.0000 - fn: 1963.0000 - accuracy: 0.6965 - precision: 0.7153 - recall: 0.6584 - auc: 0.8457 - val_loss: 0.4866 - val_tp: 497.0000 - val_fp: 98.0000 - val_tn: 1180.0000 - val_fn: 142.0000 - val_accuracy: 0.8153 - val_precision: 0.8353 - val_recall: 0.7778 - val_auc: 0.9419\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 22s 239ms/step - loss: 0.4717 - tp: 4348.0000 - fp: 942.0000 - tn: 10550.0000 - fn: 1398.0000 - accuracy: 0.7938 - precision: 0.8219 - recall: 0.7567 - auc: 0.9391 - val_loss: 0.4694 - val_tp: 472.0000 - val_fp: 76.0000 - val_tn: 1202.0000 - val_fn: 167.0000 - val_accuracy: 0.8310 - val_precision: 0.8613 - val_recall: 0.7387 - val_auc: 0.9500\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 22s 240ms/step - loss: 0.4022 - tp: 4636.0000 - fp: 825.0000 - tn: 10667.0000 - fn: 1110.0000 - accuracy: 0.8310 - precision: 0.8489 - recall: 0.8068 - auc: 0.9550 - val_loss: 0.4634 - val_tp: 475.0000 - val_fp: 141.0000 - val_tn: 1137.0000 - val_fn: 164.0000 - val_accuracy: 0.7559 - val_precision: 0.7711 - val_recall: 0.7433 - val_auc: 0.9351\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 21s 238ms/step - loss: 0.3663 - tp: 4721.0000 - fp: 767.0000 - tn: 10725.0000 - fn: 1025.0000 - accuracy: 0.8411 - precision: 0.8602 - recall: 0.8216 - auc: 0.9627 - val_loss: 0.4015 - val_tp: 507.0000 - val_fp: 69.0000 - val_tn: 1209.0000 - val_fn: 132.0000 - val_accuracy: 0.8404 - val_precision: 0.8802 - val_recall: 0.7934 - val_auc: 0.9589\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 21s 238ms/step - loss: 0.3389 - tp: 4837.0000 - fp: 690.0000 - tn: 10802.0000 - fn: 909.0000 - accuracy: 0.8597 - precision: 0.8752 - recall: 0.8418 - auc: 0.9682 - val_loss: 0.4055 - val_tp: 515.0000 - val_fp: 79.0000 - val_tn: 1199.0000 - val_fn: 124.0000 - val_accuracy: 0.8513 - val_precision: 0.8670 - val_recall: 0.8059 - val_auc: 0.9588\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 22s 241ms/step - loss: 0.2991 - tp: 4964.0000 - fp: 614.0000 - tn: 10878.0000 - fn: 782.0000 - accuracy: 0.8778 - precision: 0.8899 - recall: 0.8639 - auc: 0.9751 - val_loss: 0.3853 - val_tp: 501.0000 - val_fp: 70.0000 - val_tn: 1208.0000 - val_fn: 138.0000 - val_accuracy: 0.8466 - val_precision: 0.8774 - val_recall: 0.7840 - val_auc: 0.9613\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 22s 242ms/step - loss: 0.2843 - tp: 5019.0000 - fp: 587.0000 - tn: 10905.0000 - fn: 727.0000 - accuracy: 0.8832 - precision: 0.8953 - recall: 0.8735 - auc: 0.9775 - val_loss: 0.3646 - val_tp: 545.0000 - val_fp: 82.0000 - val_tn: 1196.0000 - val_fn: 94.0000 - val_accuracy: 0.8607 - val_precision: 0.8692 - val_recall: 0.8529 - val_auc: 0.9643\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 22s 240ms/step - loss: 0.2681 - tp: 5034.0000 - fp: 573.0000 - tn: 10919.0000 - fn: 712.0000 - accuracy: 0.8869 - precision: 0.8978 - recall: 0.8761 - auc: 0.9797 - val_loss: 0.4195 - val_tp: 491.0000 - val_fp: 127.0000 - val_tn: 1151.0000 - val_fn: 148.0000 - val_accuracy: 0.7825 - val_precision: 0.7945 - val_recall: 0.7684 - val_auc: 0.9465\n",
            "============================================\n",
            "TRAINING GPT2 : , 17\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 1.1379 - tp: 3708.0000 - fp: 1492.0000 - tn: 10000.0000 - fn: 2038.0000 - accuracy: 0.6902 - precision: 0.7131 - recall: 0.6453 - auc: 0.8446WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 36s 275ms/step - loss: 1.1379 - tp: 3708.0000 - fp: 1492.0000 - tn: 10000.0000 - fn: 2038.0000 - accuracy: 0.6902 - precision: 0.7131 - recall: 0.6453 - auc: 0.8446 - val_loss: 0.4723 - val_tp: 495.0000 - val_fp: 86.0000 - val_tn: 1192.0000 - val_fn: 144.0000 - val_accuracy: 0.8326 - val_precision: 0.8520 - val_recall: 0.7746 - val_auc: 0.9454\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 21s 238ms/step - loss: 0.4687 - tp: 4426.0000 - fp: 943.0000 - tn: 10549.0000 - fn: 1320.0000 - accuracy: 0.8016 - precision: 0.8244 - recall: 0.7703 - auc: 0.9391 - val_loss: 0.4283 - val_tp: 516.0000 - val_fp: 75.0000 - val_tn: 1203.0000 - val_fn: 123.0000 - val_accuracy: 0.8372 - val_precision: 0.8731 - val_recall: 0.8075 - val_auc: 0.9573\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 22s 241ms/step - loss: 0.3977 - tp: 4686.0000 - fp: 807.0000 - tn: 10685.0000 - fn: 1060.0000 - accuracy: 0.8355 - precision: 0.8531 - recall: 0.8155 - auc: 0.9562 - val_loss: 0.4005 - val_tp: 514.0000 - val_fp: 74.0000 - val_tn: 1204.0000 - val_fn: 125.0000 - val_accuracy: 0.8466 - val_precision: 0.8741 - val_recall: 0.8044 - val_auc: 0.9609\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 22s 239ms/step - loss: 0.3572 - tp: 4784.0000 - fp: 759.0000 - tn: 10733.0000 - fn: 962.0000 - accuracy: 0.8498 - precision: 0.8631 - recall: 0.8326 - auc: 0.9644 - val_loss: 0.3694 - val_tp: 538.0000 - val_fp: 71.0000 - val_tn: 1207.0000 - val_fn: 101.0000 - val_accuracy: 0.8607 - val_precision: 0.8834 - val_recall: 0.8419 - val_auc: 0.9653\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 22s 242ms/step - loss: 0.3393 - tp: 4835.0000 - fp: 683.0000 - tn: 10809.0000 - fn: 911.0000 - accuracy: 0.8629 - precision: 0.8762 - recall: 0.8415 - auc: 0.9680 - val_loss: 0.3846 - val_tp: 525.0000 - val_fp: 69.0000 - val_tn: 1209.0000 - val_fn: 114.0000 - val_accuracy: 0.8560 - val_precision: 0.8838 - val_recall: 0.8216 - val_auc: 0.9643\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 22s 243ms/step - loss: 0.3231 - tp: 4884.0000 - fp: 669.0000 - tn: 10823.0000 - fn: 862.0000 - accuracy: 0.8662 - precision: 0.8795 - recall: 0.8500 - auc: 0.9705 - val_loss: 0.3624 - val_tp: 540.0000 - val_fp: 81.0000 - val_tn: 1197.0000 - val_fn: 99.0000 - val_accuracy: 0.8592 - val_precision: 0.8696 - val_recall: 0.8451 - val_auc: 0.9675\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 22s 240ms/step - loss: 0.2741 - tp: 5026.0000 - fp: 554.0000 - tn: 10938.0000 - fn: 720.0000 - accuracy: 0.8883 - precision: 0.9007 - recall: 0.8747 - auc: 0.9793 - val_loss: 0.3715 - val_tp: 542.0000 - val_fp: 68.0000 - val_tn: 1210.0000 - val_fn: 97.0000 - val_accuracy: 0.8717 - val_precision: 0.8885 - val_recall: 0.8482 - val_auc: 0.9660\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 22s 242ms/step - loss: 0.2516 - tp: 5124.0000 - fp: 517.0000 - tn: 10975.0000 - fn: 622.0000 - accuracy: 0.9011 - precision: 0.9083 - recall: 0.8918 - auc: 0.9823 - val_loss: 0.3434 - val_tp: 558.0000 - val_fp: 66.0000 - val_tn: 1212.0000 - val_fn: 81.0000 - val_accuracy: 0.8811 - val_precision: 0.8942 - val_recall: 0.8732 - val_auc: 0.9700\n",
            "============================================\n",
            "TRAINING GPT2 : , 18\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 1.1180 - tp: 3589.0000 - fp: 1480.0000 - tn: 10012.0000 - fn: 2157.0000 - accuracy: 0.6831 - precision: 0.7080 - recall: 0.6246 - auc: 0.8381WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 36s 276ms/step - loss: 1.1180 - tp: 3589.0000 - fp: 1480.0000 - tn: 10012.0000 - fn: 2157.0000 - accuracy: 0.6831 - precision: 0.7080 - recall: 0.6246 - auc: 0.8381 - val_loss: 0.5040 - val_tp: 446.0000 - val_fp: 83.0000 - val_tn: 1195.0000 - val_fn: 193.0000 - val_accuracy: 0.7668 - val_precision: 0.8431 - val_recall: 0.6980 - val_auc: 0.9324\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 22s 242ms/step - loss: 0.5246 - tp: 4186.0000 - fp: 1049.0000 - tn: 10443.0000 - fn: 1560.0000 - accuracy: 0.7710 - precision: 0.7996 - recall: 0.7285 - auc: 0.9244 - val_loss: 0.5247 - val_tp: 459.0000 - val_fp: 174.0000 - val_tn: 1104.0000 - val_fn: 180.0000 - val_accuracy: 0.7214 - val_precision: 0.7251 - val_recall: 0.7183 - val_auc: 0.9225\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 22s 243ms/step - loss: 0.4392 - tp: 4471.0000 - fp: 876.0000 - tn: 10616.0000 - fn: 1275.0000 - accuracy: 0.8094 - precision: 0.8362 - recall: 0.7781 - auc: 0.9463 - val_loss: 0.4141 - val_tp: 544.0000 - val_fp: 89.0000 - val_tn: 1189.0000 - val_fn: 95.0000 - val_accuracy: 0.8545 - val_precision: 0.8594 - val_recall: 0.8513 - val_auc: 0.9585\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 22s 239ms/step - loss: 0.3657 - tp: 4711.0000 - fp: 770.0000 - tn: 10722.0000 - fn: 1035.0000 - accuracy: 0.8415 - precision: 0.8595 - recall: 0.8199 - auc: 0.9625 - val_loss: 0.3339 - val_tp: 540.0000 - val_fp: 90.0000 - val_tn: 1188.0000 - val_fn: 99.0000 - val_accuracy: 0.8513 - val_precision: 0.8571 - val_recall: 0.8451 - val_auc: 0.9688\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 22s 242ms/step - loss: 0.3818 - tp: 4623.0000 - fp: 806.0000 - tn: 10686.0000 - fn: 1123.0000 - accuracy: 0.8291 - precision: 0.8515 - recall: 0.8046 - auc: 0.9586 - val_loss: 0.3347 - val_tp: 547.0000 - val_fp: 77.0000 - val_tn: 1201.0000 - val_fn: 92.0000 - val_accuracy: 0.8685 - val_precision: 0.8766 - val_recall: 0.8560 - val_auc: 0.9701\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 22s 244ms/step - loss: 0.3524 - tp: 4746.0000 - fp: 721.0000 - tn: 10771.0000 - fn: 1000.0000 - accuracy: 0.8484 - precision: 0.8681 - recall: 0.8260 - auc: 0.9655 - val_loss: 0.3577 - val_tp: 548.0000 - val_fp: 88.0000 - val_tn: 1190.0000 - val_fn: 91.0000 - val_accuracy: 0.8576 - val_precision: 0.8616 - val_recall: 0.8576 - val_auc: 0.9684\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 22s 245ms/step - loss: 0.3114 - tp: 4878.0000 - fp: 640.0000 - tn: 10852.0000 - fn: 868.0000 - accuracy: 0.8695 - precision: 0.8840 - recall: 0.8489 - auc: 0.9729 - val_loss: 0.3240 - val_tp: 552.0000 - val_fp: 78.0000 - val_tn: 1200.0000 - val_fn: 87.0000 - val_accuracy: 0.8670 - val_precision: 0.8762 - val_recall: 0.8638 - val_auc: 0.9723\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 22s 242ms/step - loss: 0.3284 - tp: 4799.0000 - fp: 701.0000 - tn: 10791.0000 - fn: 947.0000 - accuracy: 0.8557 - precision: 0.8725 - recall: 0.8352 - auc: 0.9693 - val_loss: 0.3923 - val_tp: 529.0000 - val_fp: 102.0000 - val_tn: 1176.0000 - val_fn: 110.0000 - val_accuracy: 0.8326 - val_precision: 0.8384 - val_recall: 0.8279 - val_auc: 0.9586\n",
            "============================================\n",
            "TRAINING GPT2 : , 19\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.9548 - tp: 3663.0000 - fp: 1486.0000 - tn: 10006.0000 - fn: 2083.0000 - accuracy: 0.6847 - precision: 0.7114 - recall: 0.6375 - auc: 0.8475WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 36s 276ms/step - loss: 0.9548 - tp: 3663.0000 - fp: 1486.0000 - tn: 10006.0000 - fn: 2083.0000 - accuracy: 0.6847 - precision: 0.7114 - recall: 0.6375 - auc: 0.8475 - val_loss: 0.4680 - val_tp: 467.0000 - val_fp: 96.0000 - val_tn: 1182.0000 - val_fn: 172.0000 - val_accuracy: 0.7793 - val_precision: 0.8295 - val_recall: 0.7308 - val_auc: 0.9396\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 22s 241ms/step - loss: 0.4996 - tp: 4262.0000 - fp: 1024.0000 - tn: 10468.0000 - fn: 1484.0000 - accuracy: 0.7786 - precision: 0.8063 - recall: 0.7417 - auc: 0.9298 - val_loss: 0.4355 - val_tp: 516.0000 - val_fp: 89.0000 - val_tn: 1189.0000 - val_fn: 123.0000 - val_accuracy: 0.8451 - val_precision: 0.8529 - val_recall: 0.8075 - val_auc: 0.9504\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 22s 243ms/step - loss: 0.4219 - tp: 4527.0000 - fp: 870.0000 - tn: 10622.0000 - fn: 1219.0000 - accuracy: 0.8169 - precision: 0.8388 - recall: 0.7879 - auc: 0.9502 - val_loss: 0.4022 - val_tp: 522.0000 - val_fp: 89.0000 - val_tn: 1189.0000 - val_fn: 117.0000 - val_accuracy: 0.8357 - val_precision: 0.8543 - val_recall: 0.8169 - val_auc: 0.9579\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 22s 240ms/step - loss: 0.3959 - tp: 4603.0000 - fp: 837.0000 - tn: 10655.0000 - fn: 1143.0000 - accuracy: 0.8260 - precision: 0.8461 - recall: 0.8011 - auc: 0.9554 - val_loss: 0.3870 - val_tp: 534.0000 - val_fp: 79.0000 - val_tn: 1199.0000 - val_fn: 105.0000 - val_accuracy: 0.8638 - val_precision: 0.8711 - val_recall: 0.8357 - val_auc: 0.9603\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 22s 239ms/step - loss: 0.3557 - tp: 4767.0000 - fp: 705.0000 - tn: 10787.0000 - fn: 979.0000 - accuracy: 0.8517 - precision: 0.8712 - recall: 0.8296 - auc: 0.9645 - val_loss: 0.3830 - val_tp: 533.0000 - val_fp: 83.0000 - val_tn: 1195.0000 - val_fn: 106.0000 - val_accuracy: 0.8513 - val_precision: 0.8653 - val_recall: 0.8341 - val_auc: 0.9603\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 22s 241ms/step - loss: 0.3357 - tp: 4868.0000 - fp: 694.0000 - tn: 10798.0000 - fn: 878.0000 - accuracy: 0.8601 - precision: 0.8752 - recall: 0.8472 - auc: 0.9681 - val_loss: 0.3663 - val_tp: 540.0000 - val_fp: 82.0000 - val_tn: 1196.0000 - val_fn: 99.0000 - val_accuracy: 0.8545 - val_precision: 0.8682 - val_recall: 0.8451 - val_auc: 0.9646\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 22s 243ms/step - loss: 0.3264 - tp: 4849.0000 - fp: 695.0000 - tn: 10797.0000 - fn: 897.0000 - accuracy: 0.8615 - precision: 0.8746 - recall: 0.8439 - auc: 0.9698 - val_loss: 0.3778 - val_tp: 535.0000 - val_fp: 64.0000 - val_tn: 1214.0000 - val_fn: 104.0000 - val_accuracy: 0.8701 - val_precision: 0.8932 - val_recall: 0.8372 - val_auc: 0.9637\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 22s 244ms/step - loss: 0.2687 - tp: 5020.0000 - fp: 544.0000 - tn: 10948.0000 - fn: 726.0000 - accuracy: 0.8884 - precision: 0.9022 - recall: 0.8737 - auc: 0.9799 - val_loss: 0.4102 - val_tp: 546.0000 - val_fp: 84.0000 - val_tn: 1194.0000 - val_fn: 93.0000 - val_accuracy: 0.8576 - val_precision: 0.8667 - val_recall: 0.8545 - val_auc: 0.9602\n",
            "============================================\n",
            "TRAINING GPT2 : , 20\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 1.1645 - tp: 3700.0000 - fp: 1586.0000 - tn: 9906.0000 - fn: 2046.0000 - accuracy: 0.6801 - precision: 0.7000 - recall: 0.6439 - auc: 0.8358WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 36s 274ms/step - loss: 1.1645 - tp: 3700.0000 - fp: 1586.0000 - tn: 9906.0000 - fn: 2046.0000 - accuracy: 0.6801 - precision: 0.7000 - recall: 0.6439 - auc: 0.8358 - val_loss: 0.5335 - val_tp: 463.0000 - val_fp: 134.0000 - val_tn: 1144.0000 - val_fn: 176.0000 - val_accuracy: 0.7559 - val_precision: 0.7755 - val_recall: 0.7246 - val_auc: 0.9262\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 21s 238ms/step - loss: 0.4924 - tp: 4341.0000 - fp: 991.0000 - tn: 10501.0000 - fn: 1405.0000 - accuracy: 0.7892 - precision: 0.8141 - recall: 0.7555 - auc: 0.9331 - val_loss: 0.4799 - val_tp: 488.0000 - val_fp: 142.0000 - val_tn: 1136.0000 - val_fn: 151.0000 - val_accuracy: 0.7637 - val_precision: 0.7746 - val_recall: 0.7637 - val_auc: 0.9411\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 22s 241ms/step - loss: 0.4332 - tp: 4523.0000 - fp: 907.0000 - tn: 10585.0000 - fn: 1223.0000 - accuracy: 0.8112 - precision: 0.8330 - recall: 0.7872 - auc: 0.9480 - val_loss: 0.4552 - val_tp: 503.0000 - val_fp: 115.0000 - val_tn: 1163.0000 - val_fn: 136.0000 - val_accuracy: 0.8028 - val_precision: 0.8139 - val_recall: 0.7872 - val_auc: 0.9464\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 22s 242ms/step - loss: 0.3662 - tp: 4763.0000 - fp: 775.0000 - tn: 10717.0000 - fn: 983.0000 - accuracy: 0.8488 - precision: 0.8601 - recall: 0.8289 - auc: 0.9629 - val_loss: 0.3932 - val_tp: 527.0000 - val_fp: 101.0000 - val_tn: 1177.0000 - val_fn: 112.0000 - val_accuracy: 0.8310 - val_precision: 0.8392 - val_recall: 0.8247 - val_auc: 0.9573\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 22s 243ms/step - loss: 0.3274 - tp: 4887.0000 - fp: 690.0000 - tn: 10802.0000 - fn: 859.0000 - accuracy: 0.8643 - precision: 0.8763 - recall: 0.8505 - auc: 0.9702 - val_loss: 0.3756 - val_tp: 533.0000 - val_fp: 87.0000 - val_tn: 1191.0000 - val_fn: 106.0000 - val_accuracy: 0.8482 - val_precision: 0.8597 - val_recall: 0.8341 - val_auc: 0.9619\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 22s 244ms/step - loss: 0.2985 - tp: 4958.0000 - fp: 634.0000 - tn: 10858.0000 - fn: 788.0000 - accuracy: 0.8752 - precision: 0.8866 - recall: 0.8629 - auc: 0.9750 - val_loss: 0.5006 - val_tp: 508.0000 - val_fp: 129.0000 - val_tn: 1149.0000 - val_fn: 131.0000 - val_accuracy: 0.7966 - val_precision: 0.7975 - val_recall: 0.7950 - val_auc: 0.9492\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 22s 244ms/step - loss: 0.2811 - tp: 5019.0000 - fp: 586.0000 - tn: 10906.0000 - fn: 727.0000 - accuracy: 0.8825 - precision: 0.8955 - recall: 0.8735 - auc: 0.9779 - val_loss: 0.3689 - val_tp: 543.0000 - val_fp: 70.0000 - val_tn: 1208.0000 - val_fn: 96.0000 - val_accuracy: 0.8685 - val_precision: 0.8858 - val_recall: 0.8498 - val_auc: 0.9640\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 22s 245ms/step - loss: 0.2703 - tp: 5025.0000 - fp: 563.0000 - tn: 10929.0000 - fn: 721.0000 - accuracy: 0.8881 - precision: 0.8992 - recall: 0.8745 - auc: 0.9797 - val_loss: 0.4327 - val_tp: 523.0000 - val_fp: 83.0000 - val_tn: 1195.0000 - val_fn: 116.0000 - val_accuracy: 0.8404 - val_precision: 0.8630 - val_recall: 0.8185 - val_auc: 0.9533\n",
            "============================================\n",
            "TRAINING XLMROBERTA : , 21\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.9050 - tp: 2740.0000 - fp: 1402.0000 - tn: 10090.0000 - fn: 3006.0000 - accuracy: 0.6053 - precision: 0.6615 - recall: 0.4769 - auc: 0.7693WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 37s 287ms/step - loss: 0.9050 - tp: 2740.0000 - fp: 1402.0000 - tn: 10090.0000 - fn: 3006.0000 - accuracy: 0.6053 - precision: 0.6615 - recall: 0.4769 - auc: 0.7693 - val_loss: 0.7342 - val_tp: 241.0000 - val_fp: 44.0000 - val_tn: 1234.0000 - val_fn: 398.0000 - val_accuracy: 0.6682 - val_precision: 0.8456 - val_recall: 0.3772 - val_auc: 0.8557\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.6709 - tp: 3646.0000 - fp: 1252.0000 - tn: 10240.0000 - fn: 2100.0000 - accuracy: 0.7041 - precision: 0.7444 - recall: 0.6345 - auc: 0.8740 - val_loss: 0.6027 - val_tp: 406.0000 - val_fp: 114.0000 - val_tn: 1164.0000 - val_fn: 233.0000 - val_accuracy: 0.7246 - val_precision: 0.7808 - val_recall: 0.6354 - val_auc: 0.9037\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 22s 249ms/step - loss: 0.6199 - tp: 3842.0000 - fp: 1226.0000 - tn: 10266.0000 - fn: 1904.0000 - accuracy: 0.7261 - precision: 0.7581 - recall: 0.6686 - auc: 0.8921 - val_loss: 0.5912 - val_tp: 406.0000 - val_fp: 99.0000 - val_tn: 1179.0000 - val_fn: 233.0000 - val_accuracy: 0.7340 - val_precision: 0.8040 - val_recall: 0.6354 - val_auc: 0.9090\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.5873 - tp: 3950.0000 - fp: 1195.0000 - tn: 10297.0000 - fn: 1796.0000 - accuracy: 0.7341 - precision: 0.7677 - recall: 0.6874 - auc: 0.9019 - val_loss: 0.5434 - val_tp: 455.0000 - val_fp: 133.0000 - val_tn: 1145.0000 - val_fn: 184.0000 - val_accuracy: 0.7387 - val_precision: 0.7738 - val_recall: 0.7121 - val_auc: 0.9196\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 250ms/step - loss: 0.5661 - tp: 4051.0000 - fp: 1168.0000 - tn: 10324.0000 - fn: 1695.0000 - accuracy: 0.7492 - precision: 0.7762 - recall: 0.7050 - auc: 0.9094 - val_loss: 0.5401 - val_tp: 457.0000 - val_fp: 132.0000 - val_tn: 1146.0000 - val_fn: 182.0000 - val_accuracy: 0.7418 - val_precision: 0.7759 - val_recall: 0.7152 - val_auc: 0.9207\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.5415 - tp: 4101.0000 - fp: 1113.0000 - tn: 10379.0000 - fn: 1645.0000 - accuracy: 0.7597 - precision: 0.7865 - recall: 0.7137 - auc: 0.9163 - val_loss: 0.5426 - val_tp: 451.0000 - val_fp: 129.0000 - val_tn: 1149.0000 - val_fn: 188.0000 - val_accuracy: 0.7355 - val_precision: 0.7776 - val_recall: 0.7058 - val_auc: 0.9188\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 250ms/step - loss: 0.5463 - tp: 4138.0000 - fp: 1101.0000 - tn: 10391.0000 - fn: 1608.0000 - accuracy: 0.7633 - precision: 0.7898 - recall: 0.7202 - auc: 0.9164 - val_loss: 0.5042 - val_tp: 477.0000 - val_fp: 142.0000 - val_tn: 1136.0000 - val_fn: 162.0000 - val_accuracy: 0.7606 - val_precision: 0.7706 - val_recall: 0.7465 - val_auc: 0.9291\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.5251 - tp: 4156.0000 - fp: 1091.0000 - tn: 10401.0000 - fn: 1590.0000 - accuracy: 0.7652 - precision: 0.7921 - recall: 0.7233 - auc: 0.9221 - val_loss: 0.5315 - val_tp: 456.0000 - val_fp: 123.0000 - val_tn: 1155.0000 - val_fn: 183.0000 - val_accuracy: 0.7512 - val_precision: 0.7876 - val_recall: 0.7136 - val_auc: 0.9219\n",
            "============================================\n",
            "TRAINING XLMROBERTA : , 22\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8905 - tp: 2805.0000 - fp: 1554.0000 - tn: 9938.0000 - fn: 2941.0000 - accuracy: 0.6011 - precision: 0.6435 - recall: 0.4882 - auc: 0.7756WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 38s 289ms/step - loss: 0.8905 - tp: 2805.0000 - fp: 1554.0000 - tn: 9938.0000 - fn: 2941.0000 - accuracy: 0.6011 - precision: 0.6435 - recall: 0.4882 - auc: 0.7756 - val_loss: 0.7005 - val_tp: 357.0000 - val_fp: 117.0000 - val_tn: 1161.0000 - val_fn: 282.0000 - val_accuracy: 0.6917 - val_precision: 0.7532 - val_recall: 0.5587 - val_auc: 0.8672\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.6685 - tp: 3717.0000 - fp: 1378.0000 - tn: 10114.0000 - fn: 2029.0000 - accuracy: 0.7017 - precision: 0.7295 - recall: 0.6469 - auc: 0.8733 - val_loss: 0.5872 - val_tp: 402.0000 - val_fp: 76.0000 - val_tn: 1202.0000 - val_fn: 237.0000 - val_accuracy: 0.7715 - val_precision: 0.8410 - val_recall: 0.6291 - val_auc: 0.9216\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.6287 - tp: 3809.0000 - fp: 1298.0000 - tn: 10194.0000 - fn: 1937.0000 - accuracy: 0.7168 - precision: 0.7458 - recall: 0.6629 - auc: 0.8882 - val_loss: 0.5400 - val_tp: 476.0000 - val_fp: 121.0000 - val_tn: 1157.0000 - val_fn: 163.0000 - val_accuracy: 0.7731 - val_precision: 0.7973 - val_recall: 0.7449 - val_auc: 0.9281\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 22s 248ms/step - loss: 0.5947 - tp: 3983.0000 - fp: 1278.0000 - tn: 10214.0000 - fn: 1763.0000 - accuracy: 0.7297 - precision: 0.7571 - recall: 0.6932 - auc: 0.8998 - val_loss: 0.5367 - val_tp: 477.0000 - val_fp: 106.0000 - val_tn: 1172.0000 - val_fn: 162.0000 - val_accuracy: 0.7825 - val_precision: 0.8182 - val_recall: 0.7465 - val_auc: 0.9294\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 22s 249ms/step - loss: 0.5769 - tp: 4036.0000 - fp: 1205.0000 - tn: 10287.0000 - fn: 1710.0000 - accuracy: 0.7393 - precision: 0.7701 - recall: 0.7024 - auc: 0.9058 - val_loss: 0.5109 - val_tp: 486.0000 - val_fp: 108.0000 - val_tn: 1170.0000 - val_fn: 153.0000 - val_accuracy: 0.7825 - val_precision: 0.8182 - val_recall: 0.7606 - val_auc: 0.9365\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 22s 250ms/step - loss: 0.5499 - tp: 4109.0000 - fp: 1163.0000 - tn: 10329.0000 - fn: 1637.0000 - accuracy: 0.7579 - precision: 0.7794 - recall: 0.7151 - auc: 0.9146 - val_loss: 0.5198 - val_tp: 455.0000 - val_fp: 74.0000 - val_tn: 1204.0000 - val_fn: 184.0000 - val_accuracy: 0.7903 - val_precision: 0.8601 - val_recall: 0.7121 - val_auc: 0.9397\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 249ms/step - loss: 0.5370 - tp: 4156.0000 - fp: 1126.0000 - tn: 10366.0000 - fn: 1590.0000 - accuracy: 0.7586 - precision: 0.7868 - recall: 0.7233 - auc: 0.9182 - val_loss: 0.4805 - val_tp: 497.0000 - val_fp: 105.0000 - val_tn: 1173.0000 - val_fn: 142.0000 - val_accuracy: 0.7981 - val_precision: 0.8256 - val_recall: 0.7778 - val_auc: 0.9441\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 22s 248ms/step - loss: 0.5191 - tp: 4206.0000 - fp: 1122.0000 - tn: 10370.0000 - fn: 1540.0000 - accuracy: 0.7680 - precision: 0.7894 - recall: 0.7320 - auc: 0.9230 - val_loss: 0.4666 - val_tp: 498.0000 - val_fp: 101.0000 - val_tn: 1177.0000 - val_fn: 141.0000 - val_accuracy: 0.8028 - val_precision: 0.8314 - val_recall: 0.7793 - val_auc: 0.9465\n",
            "============================================\n",
            "TRAINING XLMROBERTA : , 23\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8644 - tp: 2875.0000 - fp: 1515.0000 - tn: 9977.0000 - fn: 2871.0000 - accuracy: 0.6089 - precision: 0.6549 - recall: 0.5003 - auc: 0.7870WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 38s 284ms/step - loss: 0.8644 - tp: 2875.0000 - fp: 1515.0000 - tn: 9977.0000 - fn: 2871.0000 - accuracy: 0.6089 - precision: 0.6549 - recall: 0.5003 - auc: 0.7870 - val_loss: 0.7203 - val_tp: 358.0000 - val_fp: 142.0000 - val_tn: 1136.0000 - val_fn: 281.0000 - val_accuracy: 0.6620 - val_precision: 0.7160 - val_recall: 0.5603 - val_auc: 0.8546\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 22s 248ms/step - loss: 0.6715 - tp: 3669.0000 - fp: 1290.0000 - tn: 10202.0000 - fn: 2077.0000 - accuracy: 0.7007 - precision: 0.7399 - recall: 0.6385 - auc: 0.8727 - val_loss: 0.6112 - val_tp: 429.0000 - val_fp: 141.0000 - val_tn: 1137.0000 - val_fn: 210.0000 - val_accuracy: 0.7230 - val_precision: 0.7526 - val_recall: 0.6714 - val_auc: 0.8980\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 250ms/step - loss: 0.6328 - tp: 3826.0000 - fp: 1293.0000 - tn: 10199.0000 - fn: 1920.0000 - accuracy: 0.7155 - precision: 0.7474 - recall: 0.6659 - auc: 0.8863 - val_loss: 0.6300 - val_tp: 432.0000 - val_fp: 158.0000 - val_tn: 1120.0000 - val_fn: 207.0000 - val_accuracy: 0.7089 - val_precision: 0.7322 - val_recall: 0.6761 - val_auc: 0.8892\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 22s 250ms/step - loss: 0.5976 - tp: 3930.0000 - fp: 1230.0000 - tn: 10262.0000 - fn: 1816.0000 - accuracy: 0.7329 - precision: 0.7616 - recall: 0.6840 - auc: 0.8982 - val_loss: 0.5462 - val_tp: 466.0000 - val_fp: 144.0000 - val_tn: 1134.0000 - val_fn: 173.0000 - val_accuracy: 0.7465 - val_precision: 0.7639 - val_recall: 0.7293 - val_auc: 0.9170\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.5672 - tp: 4031.0000 - fp: 1167.0000 - tn: 10325.0000 - fn: 1715.0000 - accuracy: 0.7436 - precision: 0.7755 - recall: 0.7015 - auc: 0.9083 - val_loss: 0.5799 - val_tp: 457.0000 - val_fp: 149.0000 - val_tn: 1129.0000 - val_fn: 182.0000 - val_accuracy: 0.7371 - val_precision: 0.7541 - val_recall: 0.7152 - val_auc: 0.9080\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 250ms/step - loss: 0.5614 - tp: 4084.0000 - fp: 1171.0000 - tn: 10321.0000 - fn: 1662.0000 - accuracy: 0.7478 - precision: 0.7772 - recall: 0.7108 - auc: 0.9106 - val_loss: 0.5861 - val_tp: 446.0000 - val_fp: 141.0000 - val_tn: 1137.0000 - val_fn: 193.0000 - val_accuracy: 0.7387 - val_precision: 0.7598 - val_recall: 0.6980 - val_auc: 0.9076\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.5459 - tp: 4130.0000 - fp: 1127.0000 - tn: 10365.0000 - fn: 1616.0000 - accuracy: 0.7581 - precision: 0.7856 - recall: 0.7188 - auc: 0.9160 - val_loss: 0.5921 - val_tp: 454.0000 - val_fp: 154.0000 - val_tn: 1124.0000 - val_fn: 185.0000 - val_accuracy: 0.7371 - val_precision: 0.7467 - val_recall: 0.7105 - val_auc: 0.9049\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 250ms/step - loss: 0.5326 - tp: 4178.0000 - fp: 1105.0000 - tn: 10387.0000 - fn: 1568.0000 - accuracy: 0.7649 - precision: 0.7908 - recall: 0.7271 - auc: 0.9201 - val_loss: 0.5412 - val_tp: 456.0000 - val_fp: 125.0000 - val_tn: 1153.0000 - val_fn: 183.0000 - val_accuracy: 0.7700 - val_precision: 0.7849 - val_recall: 0.7136 - val_auc: 0.9197\n",
            "============================================\n",
            "TRAINING XLMROBERTA : , 24\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8981 - tp: 2813.0000 - fp: 1573.0000 - tn: 9919.0000 - fn: 2933.0000 - accuracy: 0.5971 - precision: 0.6414 - recall: 0.4896 - auc: 0.7713WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 40s 291ms/step - loss: 0.8981 - tp: 2813.0000 - fp: 1573.0000 - tn: 9919.0000 - fn: 2933.0000 - accuracy: 0.5971 - precision: 0.6414 - recall: 0.4896 - auc: 0.7713 - val_loss: 0.6672 - val_tp: 440.0000 - val_fp: 156.0000 - val_tn: 1122.0000 - val_fn: 199.0000 - val_accuracy: 0.7230 - val_precision: 0.7383 - val_recall: 0.6886 - val_auc: 0.8838\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 23s 250ms/step - loss: 0.6825 - tp: 3679.0000 - fp: 1325.0000 - tn: 10167.0000 - fn: 2067.0000 - accuracy: 0.7029 - precision: 0.7352 - recall: 0.6403 - auc: 0.8693 - val_loss: 0.6174 - val_tp: 434.0000 - val_fp: 143.0000 - val_tn: 1135.0000 - val_fn: 205.0000 - val_accuracy: 0.7293 - val_precision: 0.7522 - val_recall: 0.6792 - val_auc: 0.8986\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 250ms/step - loss: 0.6213 - tp: 3895.0000 - fp: 1301.0000 - tn: 10191.0000 - fn: 1851.0000 - accuracy: 0.7226 - precision: 0.7496 - recall: 0.6779 - auc: 0.8911 - val_loss: 0.6236 - val_tp: 428.0000 - val_fp: 143.0000 - val_tn: 1135.0000 - val_fn: 211.0000 - val_accuracy: 0.7152 - val_precision: 0.7496 - val_recall: 0.6698 - val_auc: 0.8912\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.6000 - tp: 3935.0000 - fp: 1268.0000 - tn: 10224.0000 - fn: 1811.0000 - accuracy: 0.7285 - precision: 0.7563 - recall: 0.6848 - auc: 0.8974 - val_loss: 0.6456 - val_tp: 386.0000 - val_fp: 129.0000 - val_tn: 1149.0000 - val_fn: 253.0000 - val_accuracy: 0.6854 - val_precision: 0.7495 - val_recall: 0.6041 - val_auc: 0.8792\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.5710 - tp: 4027.0000 - fp: 1209.0000 - tn: 10283.0000 - fn: 1719.0000 - accuracy: 0.7452 - precision: 0.7691 - recall: 0.7008 - auc: 0.9078 - val_loss: 0.5522 - val_tp: 461.0000 - val_fp: 138.0000 - val_tn: 1140.0000 - val_fn: 178.0000 - val_accuracy: 0.7480 - val_precision: 0.7696 - val_recall: 0.7214 - val_auc: 0.9151\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.5596 - tp: 4072.0000 - fp: 1154.0000 - tn: 10338.0000 - fn: 1674.0000 - accuracy: 0.7492 - precision: 0.7792 - recall: 0.7087 - auc: 0.9106 - val_loss: 0.5375 - val_tp: 474.0000 - val_fp: 141.0000 - val_tn: 1137.0000 - val_fn: 165.0000 - val_accuracy: 0.7590 - val_precision: 0.7707 - val_recall: 0.7418 - val_auc: 0.9195\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.5323 - tp: 4201.0000 - fp: 1140.0000 - tn: 10352.0000 - fn: 1545.0000 - accuracy: 0.7630 - precision: 0.7866 - recall: 0.7311 - auc: 0.9201 - val_loss: 0.5095 - val_tp: 481.0000 - val_fp: 137.0000 - val_tn: 1141.0000 - val_fn: 158.0000 - val_accuracy: 0.7621 - val_precision: 0.7783 - val_recall: 0.7527 - val_auc: 0.9258\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.5235 - tp: 4212.0000 - fp: 1149.0000 - tn: 10343.0000 - fn: 1534.0000 - accuracy: 0.7656 - precision: 0.7857 - recall: 0.7330 - auc: 0.9219 - val_loss: 0.5190 - val_tp: 462.0000 - val_fp: 138.0000 - val_tn: 1140.0000 - val_fn: 177.0000 - val_accuracy: 0.7574 - val_precision: 0.7700 - val_recall: 0.7230 - val_auc: 0.9236\n",
            "============================================\n",
            "TRAINING XLMROBERTA : , 25\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8946 - tp: 2857.0000 - fp: 1521.0000 - tn: 9971.0000 - fn: 2889.0000 - accuracy: 0.6062 - precision: 0.6526 - recall: 0.4972 - auc: 0.7758WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "90/90 [==============================] - 38s 286ms/step - loss: 0.8946 - tp: 2857.0000 - fp: 1521.0000 - tn: 9971.0000 - fn: 2889.0000 - accuracy: 0.6062 - precision: 0.6526 - recall: 0.4972 - auc: 0.7758 - val_loss: 0.7628 - val_tp: 342.0000 - val_fp: 140.0000 - val_tn: 1138.0000 - val_fn: 297.0000 - val_accuracy: 0.6510 - val_precision: 0.7095 - val_recall: 0.5352 - val_auc: 0.8311\n",
            "Epoch 2/8\n",
            "90/90 [==============================] - 22s 249ms/step - loss: 0.6672 - tp: 3632.0000 - fp: 1318.0000 - tn: 10174.0000 - fn: 2114.0000 - accuracy: 0.6998 - precision: 0.7337 - recall: 0.6321 - auc: 0.8734 - val_loss: 0.5975 - val_tp: 434.0000 - val_fp: 125.0000 - val_tn: 1153.0000 - val_fn: 205.0000 - val_accuracy: 0.7371 - val_precision: 0.7764 - val_recall: 0.6792 - val_auc: 0.9054\n",
            "Epoch 3/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.6307 - tp: 3826.0000 - fp: 1231.0000 - tn: 10261.0000 - fn: 1920.0000 - accuracy: 0.7221 - precision: 0.7566 - recall: 0.6659 - auc: 0.8886 - val_loss: 0.5524 - val_tp: 461.0000 - val_fp: 138.0000 - val_tn: 1140.0000 - val_fn: 178.0000 - val_accuracy: 0.7449 - val_precision: 0.7696 - val_recall: 0.7214 - val_auc: 0.9173\n",
            "Epoch 4/8\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.6060 - tp: 3917.0000 - fp: 1264.0000 - tn: 10228.0000 - fn: 1829.0000 - accuracy: 0.7329 - precision: 0.7560 - recall: 0.6817 - auc: 0.8964 - val_loss: 0.5230 - val_tp: 481.0000 - val_fp: 145.0000 - val_tn: 1133.0000 - val_fn: 158.0000 - val_accuracy: 0.7653 - val_precision: 0.7684 - val_recall: 0.7527 - val_auc: 0.9272\n",
            "Epoch 5/8\n",
            "90/90 [==============================] - 23s 250ms/step - loss: 0.5849 - tp: 3975.0000 - fp: 1228.0000 - tn: 10264.0000 - fn: 1771.0000 - accuracy: 0.7346 - precision: 0.7640 - recall: 0.6918 - auc: 0.9029 - val_loss: 0.5138 - val_tp: 482.0000 - val_fp: 145.0000 - val_tn: 1133.0000 - val_fn: 157.0000 - val_accuracy: 0.7668 - val_precision: 0.7687 - val_recall: 0.7543 - val_auc: 0.9309\n",
            "Epoch 6/8\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.5660 - tp: 4043.0000 - fp: 1166.0000 - tn: 10326.0000 - fn: 1703.0000 - accuracy: 0.7457 - precision: 0.7762 - recall: 0.7036 - auc: 0.9093 - val_loss: 0.5262 - val_tp: 486.0000 - val_fp: 145.0000 - val_tn: 1133.0000 - val_fn: 153.0000 - val_accuracy: 0.7700 - val_precision: 0.7702 - val_recall: 0.7606 - val_auc: 0.9288\n",
            "Epoch 7/8\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.5459 - tp: 4103.0000 - fp: 1157.0000 - tn: 10335.0000 - fn: 1643.0000 - accuracy: 0.7553 - precision: 0.7800 - recall: 0.7141 - auc: 0.9155 - val_loss: 0.4925 - val_tp: 486.0000 - val_fp: 108.0000 - val_tn: 1170.0000 - val_fn: 153.0000 - val_accuracy: 0.7856 - val_precision: 0.8182 - val_recall: 0.7606 - val_auc: 0.9341\n",
            "Epoch 8/8\n",
            "90/90 [==============================] - 23s 250ms/step - loss: 0.5266 - tp: 4182.0000 - fp: 1111.0000 - tn: 10381.0000 - fn: 1564.0000 - accuracy: 0.7671 - precision: 0.7901 - recall: 0.7278 - auc: 0.9217 - val_loss: 0.4858 - val_tp: 493.0000 - val_fp: 139.0000 - val_tn: 1139.0000 - val_fn: 146.0000 - val_accuracy: 0.7778 - val_precision: 0.7801 - val_recall: 0.7715 - val_auc: 0.9349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToK9uT3o6HSM"
      },
      "source": [
        "dfResultTransformer =  pd.DataFrame(FinalHistory_Transformers,columns=[ \"rataAccTrain\", \"rataAccVal\",\n",
        "                    \"rataLossTrain\", \"rataLossVal\",\n",
        "                    \"precisionTrain\",\"precisionVal\",\n",
        "                    \"recallTrain\",\"recallVal\",\"ModelName\"])\n",
        "\n",
        "dfResultTransformer.to_excel(\"ResultTransformerMerged.xlsx\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5o0OknvrAK1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0a57f225-058a-4a8d-d52b-d82f4ad4f544"
      },
      "source": [
        "dfResultTransformer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rataAccTrain</th>\n",
              "      <th>rataAccVal</th>\n",
              "      <th>rataLossTrain</th>\n",
              "      <th>rataLossVal</th>\n",
              "      <th>precisionTrain</th>\n",
              "      <th>precisionVal</th>\n",
              "      <th>recallTrain</th>\n",
              "      <th>recallVal</th>\n",
              "      <th>ModelName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.856287</td>\n",
              "      <td>0.865728</td>\n",
              "      <td>0.368437</td>\n",
              "      <td>0.341393</td>\n",
              "      <td>0.870986</td>\n",
              "      <td>0.877931</td>\n",
              "      <td>0.837674</td>\n",
              "      <td>0.852465</td>\n",
              "      <td>IndoBert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.823542</td>\n",
              "      <td>0.822027</td>\n",
              "      <td>0.422672</td>\n",
              "      <td>0.418194</td>\n",
              "      <td>0.839221</td>\n",
              "      <td>0.828614</td>\n",
              "      <td>0.801371</td>\n",
              "      <td>0.814906</td>\n",
              "      <td>Roberta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.716498</td>\n",
              "      <td>0.714632</td>\n",
              "      <td>0.660200</td>\n",
              "      <td>0.649035</td>\n",
              "      <td>0.761730</td>\n",
              "      <td>0.749635</td>\n",
              "      <td>0.643548</td>\n",
              "      <td>0.667958</td>\n",
              "      <td>Bert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.827014</td>\n",
              "      <td>0.832825</td>\n",
              "      <td>0.451227</td>\n",
              "      <td>0.412087</td>\n",
              "      <td>0.844827</td>\n",
              "      <td>0.850568</td>\n",
              "      <td>0.803137</td>\n",
              "      <td>0.808959</td>\n",
              "      <td>GPT2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.722259</td>\n",
              "      <td>0.743701</td>\n",
              "      <td>0.622771</td>\n",
              "      <td>0.571626</td>\n",
              "      <td>0.753079</td>\n",
              "      <td>0.777756</td>\n",
              "      <td>0.668017</td>\n",
              "      <td>0.693505</td>\n",
              "      <td>XLMROBERTA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rataAccTrain  rataAccVal  rataLossTrain  ...  recallTrain  recallVal   ModelName\n",
              "0      0.856287    0.865728       0.368437  ...     0.837674   0.852465    IndoBert\n",
              "1      0.823542    0.822027       0.422672  ...     0.801371   0.814906     Roberta\n",
              "2      0.716498    0.714632       0.660200  ...     0.643548   0.667958        Bert\n",
              "3      0.827014    0.832825       0.451227  ...     0.803137   0.808959        GPT2\n",
              "4      0.722259    0.743701       0.622771  ...     0.668017   0.693505  XLMROBERTA\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4svaHXqWd3J"
      },
      "source": [
        "step = len(token_train_XLMRoberta[\"tweet\"][\"input_ids\"]) // 64\n",
        "def initModelAttentions():\n",
        "  dataForIndoBert = \n",
        "def trainBert(EPOCHS,CALLBACKS):\n",
        "  history = bertmodelObj.fit(train_databert,steps_per_epoch = step, validation_data=validation_databert,epochs=EPOCHS)\n",
        "  return history\n",
        "\n",
        "def trainRoberta(EPOCHS,CALLBACKS):\n",
        "  history = robertaModelObj.fit(train_dataRoberta,steps_per_epoch = step,validation_data=validation_dataRoberta,epochs=EPOCHS)\n",
        "  return history\n",
        "\n",
        "def trainXlmRoberta(EPOCHS, CALLBACKS):\n",
        "  history = xlmRobertaModelObj.fit(train_dataXLMRoberta,steps_per_epoch = step,validation_data = validation_dataXLMRoberta,epochs=EPOCHS)\n",
        "  return history\n",
        "\n",
        "def trainGpt2(EPOCHS, CALLBACKS):\n",
        "  history = GPT2ModelObj.fit(train_dataGPT2,steps_per_epoch = step, validation_data = validation_dataGPT2,epochs = EPOCHS)\n",
        "  return history\n",
        "\n",
        "def trainIndoBert(EPOCHS, CALLBACKS):\n",
        "  history = indobertModelObj.fit(datasetTraining,steps_per_epoch = step, validation_data = datasetValidation, epochs= EPOCHS)\n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8oV7-RN5qoX"
      },
      "source": [
        "print(y_train)\n",
        "pred =np.argmax(indobertModelObj.predict(datasetTraining,steps=step),axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcQTq7lWAWDF"
      },
      "source": [
        "y_trainCopy = np.argmax(y_train.copy(),axis=1)\n",
        "y_trainCopy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c55YqEqBCK0O"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_trainCopy[:5888],pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoWDXq5g_0GK"
      },
      "source": [
        "def getDifferTrainingIndoBert():\n",
        "  differ = []\n",
        "  for indx,content in enumerate(x_train.loc[:5888,\"tweet\"].values):\n",
        "     if (y_trainCopy[indx] != pred[indx]):\n",
        "       differ.append( (x_train.iloc[indx,0],f\"TRUE : {y_trainCopy[indx]}\",f\"PRED {pred[indx]}\" ))\n",
        "  return differ\n",
        "pd.DataFrame(getDifferTrainingIndoBert()).to_excel(\"Klasifikasi yang SalahIndoBert.xlsx\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQR3Cp7QG7YY"
      },
      "source": [
        "def getDifferTrainingLSTM():\n",
        "  differ = []\n",
        "  for indx,content in enumerate(x_trainlstm.loc[:,\"tweet\"].values):\n",
        "     if (y_trainlstm[indx] != pred[indx]):\n",
        "       differ.append( (x_train.x_trainlstm[indx,0],f\"TRUE : {y_trainlstm[indx]}\",f\"PRED {pred[indx]}\" ))\n",
        "  return differ\n",
        "pd.DataFrame(getDifferTrainingIndoBert()).to_excel(\"Klasifikasi yang SalahLSTM.xlsx\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs2DgUjwuo4M"
      },
      "source": [
        "def plotlah(history,modelName):\n",
        "  import plotly.graph_objects as go\n",
        "  fig = go.Figure()\n",
        "  history.history[\"epochs\"] = list(range(1,10))\n",
        "  fig.add_trace(go.Scatter(y= history.history[\"accuracy\"],x= history.history[\"epochs\"],mode=\"lines+markers\",name=\"Training acc\"))\n",
        "  fig.add_trace(go.Scatter(y= history.history[\"val_accuracy\"],x= history.history[\"epochs\"],mode=\"lines+markers\",name=\"Val acc\"))\n",
        "  fig.update_layout(title=modelName)\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMeWSGd0_Cn6"
      },
      "source": [
        "### NOn Ettention\n",
        "lstmHistory = lstm.fit(x_trainlstm,y_trainlstm,epochs=10,\n",
        "                       validation_data=(x_valLstm,y_valLstm))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrIS5GgPDgN5"
      },
      "source": [
        "plotlah(bertHistory,\"IndoBert\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGhRMzvUAYPb"
      },
      "source": [
        "plotlah(lstmHistory,\"LSTM WITHOUT GRU\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHsUnlmyANNQ"
      },
      "source": [
        "lstm_pred = np.argmax(lstm.predict(x_trainlstm),axis=1)\n",
        "y_trainlstmRill = np.argmax(y_trainlstm,axis=1)\n",
        "\n",
        "def confusionGelo(y_true,ypred):\n",
        "  print(confusion_matrix(y_true,ypred))\n",
        "print(\"ConfusionMatrixLSTM\")\n",
        "confusionGelo(y_trainlstmRill,lstm_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iytztfV-I3oe"
      },
      "source": [
        "print(\"ConfusionMatrixTransformers\")\n",
        "confusionGelo(np.argmax(y_train[:5888],axis=1),pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hm3c6niznYhT",
        "outputId": "fb18031b-fd28-41bb-f292-e29632075d6b"
      },
      "source": [
        "FinalHistory_Transformers = []\n",
        "trainedTransformerModels = []\n",
        "splits = 5\n",
        "EPOCHS = 8\n",
        "def TrainAttentions(splits,EPOCHS):\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  skf = StratifiedKFold(n_splits=splits)\n",
        "  fold = 1\n",
        "  #y_train= np.argmax(y_train,axis=1)\n",
        "  historyList = [] \n",
        "  bertmodelObj,indobertModelObj,robertaModelObj,xlmRobertaModelObj,GPT2ModelObj = initModel()\n",
        "  #modelNames = [\"IndoBert\",\"Roberta\",\"Bert\",\"GPT2\",\"XLMROBERTA\"]\n",
        "  #modelTransformers = [indobertModelObj,robertaModelObj,bertmodelObj,GPT2Model,xlmRobertaModelObj]\n",
        "  #dataTransformers = [dataforIndoBertAttention(),dataforRobertaAttention(),dataforBertAttentions(),dataforGPT2Attentions(),dataforXLMRoBERTaAttention()]\n",
        "  modelNames = [\"XLMROBERTA\"]\n",
        "  modelTransformers = [xlmRobertaModelObj]\n",
        "  dataTransformers = [dataforXLMRoBERTaAttention()]\n",
        "  for modelname, model,content in zip(modelNames,modelTransformers,dataTransformers):\n",
        "    HISTORY_TRANSFORMERS = []\n",
        "    for train_indx, val_indx in skf.split(content[0][\"tweet\"],np.argmax(content[1],axis=1)):\n",
        "      print(\"============================================\")\n",
        "      print(f\"TRAINING {modelname} : , {fold}\" )\n",
        "      if (modelname == \"IndoBert\"):\n",
        "        model = indoBertModel()\n",
        "      elif (modelname==\"Roberta\"):\n",
        "        model = robertaModel()\n",
        "      elif (modelname == \"Bert\"):\n",
        "        model = bertModel()\n",
        "      elif (modelname == \"GPT2\"):\n",
        "        model = GPT2Model()\n",
        "      elif (modelname == \"XLMROBERTA\"):\n",
        "        model = XlmRoberta()\n",
        "      train = content[0][\"tweet\"][train_indx]\n",
        "      trainMask = content[0][\"tweetMask\"][train_indx]\n",
        "      val = content[0][\"tweet\"][val_indx]\n",
        "      valMask = content[0][\"tweetMask\"][val_indx]\n",
        "      dataTrain = {\n",
        "          \"tweet\" : train,\n",
        "          \"tweetMask\" :trainMask \n",
        "      }\n",
        "      dataVal = {\n",
        "          \"tweet\" : val,\n",
        "          \"tweetMask\" : valMask\n",
        "      }\n",
        "      ytrain = content[1][train_indx] \n",
        "      yval = content[1][val_indx]\n",
        "      trainData = (tf.data.Dataset.from_tensor_slices((dataTrain,ytrain))).batch(64).prefetch(AUTO)\n",
        "      valData = (tf.data.Dataset.from_tensor_slices((dataVal,yval))).batch(64).prefetch(AUTO).cache()\n",
        "      history = model.fit( (trainData),validation_data = valData,epochs=EPOCHS)\n",
        "      data = (\"rataAccTrain\", \"rataAccVal\",\n",
        "                    \"rataLossTrain\", \"rataLossVal\",\n",
        "                    \"precisionTrain\",\"precisionVal\",\n",
        "                    \"recallTrain\",\"recallVal\",\"f1ScoreTrain\",\"f1ScoreVal\")\n",
        "      datBang = [ (np.mean(history.history[\"accuracy\"]), np.mean(history.history[\"val_accuracy\"]),\n",
        "                         np.mean(history.history[\"loss\"]), np.mean(history.history[\"val_loss\"]),\n",
        "                         np.mean(history.history[\"precision\"]), np.mean(history.history[\"val_precision\"]),\n",
        "                         np.mean(history.history[\"recall\"]), np.mean(history.history[\"val_recall\"]) )  ]\n",
        "      HISTORY_TRANSFORMERS.append(datBang)\n",
        "      fold += 1\n",
        "    hist = np.array(HISTORY_TRANSFORMERS,dtype=np.float32).reshape(splits,EPOCHS)\n",
        "    data = (hist[:,0].mean(),hist[:,1].mean(),hist[:,2].mean(),\n",
        "                hist[:,3].mean(),hist[:,4].mean(),hist[:,5].mean(),\n",
        "                hist[:,6].mean(),hist[:,7].mean(),modelname)\n",
        "    FinalHistory_Transformers.append((data))\n",
        "    trainedTransformerModels.append(model)\n",
        "TrainAttentions(splits,EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x7fc28d0b0b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 546, in __del__\n",
            "    handle=self._handle, deleter=self._deleter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1264, in delete_iterator\n",
            "    _ctx, \"DeleteIterator\", name, handle, deleter)\n",
            "KeyboardInterrupt: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning:\n",
            "\n",
            "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "============================================\n",
            "TRAINING XLMROBERTA : , 1\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Epoch 1/8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "80/80 [==============================] - ETA: 0s - loss: 1.0669 - tp: 1197.0000 - fp: 1116.0000 - tn: 9100.0000 - fn: 3911.0000 - accuracy: 0.4614 - precision: 0.5175 - recall: 0.2343 - auc: 0.6331WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "80/80 [==============================] - 41s 332ms/step - loss: 1.0669 - tp: 1197.0000 - fp: 1116.0000 - tn: 9100.0000 - fn: 3911.0000 - accuracy: 0.4614 - precision: 0.5175 - recall: 0.2343 - auc: 0.6331 - val_loss: 1.0065 - val_tp: 481.0000 - val_fp: 371.0000 - val_tn: 2183.0000 - val_fn: 796.0000 - val_accuracy: 0.5348 - val_precision: 0.5646 - val_recall: 0.3767 - val_auc: 0.6863\n",
            "Epoch 2/8\n",
            "80/80 [==============================] - 23s 285ms/step - loss: 1.0288 - tp: 1390.0000 - fp: 1161.0000 - tn: 9055.0000 - fn: 3718.0000 - accuracy: 0.5008 - precision: 0.5449 - recall: 0.2721 - auc: 0.6643 - val_loss: 0.9939 - val_tp: 464.0000 - val_fp: 357.0000 - val_tn: 2197.0000 - val_fn: 813.0000 - val_accuracy: 0.5521 - val_precision: 0.5652 - val_recall: 0.3634 - val_auc: 0.7068\n",
            "Epoch 3/8\n",
            "80/80 [==============================] - 22s 279ms/step - loss: 1.0087 - tp: 1553.0000 - fp: 1206.0000 - tn: 9010.0000 - fn: 3555.0000 - accuracy: 0.5204 - precision: 0.5629 - recall: 0.3040 - auc: 0.6820 - val_loss: 0.9734 - val_tp: 448.0000 - val_fp: 336.0000 - val_tn: 2218.0000 - val_fn: 829.0000 - val_accuracy: 0.5607 - val_precision: 0.5714 - val_recall: 0.3508 - val_auc: 0.7187\n",
            "Epoch 4/8\n",
            "80/80 [==============================] - 22s 277ms/step - loss: 0.9964 - tp: 1739.0000 - fp: 1327.0000 - tn: 8889.0000 - fn: 3369.0000 - accuracy: 0.5290 - precision: 0.5672 - recall: 0.3404 - auc: 0.6925 - val_loss: 0.9728 - val_tp: 389.0000 - val_fp: 263.0000 - val_tn: 2291.0000 - val_fn: 888.0000 - val_accuracy: 0.5826 - val_precision: 0.5966 - val_recall: 0.3046 - val_auc: 0.7288\n",
            "Epoch 5/8\n",
            "80/80 [==============================] - ETA: 0s - loss: 0.9972 - tp: 1732.0000 - fp: 1247.0000 - tn: 8969.0000 - fn: 3376.0000 - accuracy: 0.5305 - precision: 0.5814 - recall: 0.3391 - auc: 0.6919"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-e50f63a4b930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mFinalHistory_Transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mtrainedTransformerModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mTrainAttentions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-81-e50f63a4b930>\u001b[0m in \u001b[0;36mTrainAttentions\u001b[0;34m(splits, EPOCHS)\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0mtrainData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mvalData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataVal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m       \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m       data = (\"rataAccTrain\", \"rataAccVal\",\n\u001b[1;32m     51\u001b[0m                     \u001b[0;34m\"rataLossTrain\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rataLossVal\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1223\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1226\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTIT850pXNal"
      },
      "source": [
        "WORD_SIZE = 5000\n",
        "X,Y = dataForLstm()\n",
        "model = lstmModel(50)\n",
        "EPOCHS = 8\n",
        "history = model.fit(x=X,y=Y ,validation_split = 0.20,batch_size=64,epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgKT3QBvWJHM",
        "outputId": "7df39cd9-32b7-45c9-8614-fc5bd0b72c97"
      },
      "source": [
        "!gdown --id 1qsgKjgJhG1NO0kmUbg5LvGf0SNXckPoU\n",
        "def dataForLstmtest():\n",
        "  from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "  tokenizer = Tokenizer(num_words = WORD_SIZE)\n",
        "  tokenizer.fit_on_texts(dfAllData[\"tweet\"].values)\n",
        "  X = tokenizer.texts_to_sequences(dfAllData[\"tweet\"].values)\n",
        "  X = tf.keras.preprocessing.sequence.pad_sequences(X,maxlen=MAX_LENGTHS)\n",
        "  Ylstm = tf.keras.utils.to_categorical(dfAllData[\"labels\"])\n",
        "  return tokenizer\n",
        "tokenizerTest = dataForLstmtest()\n",
        "test = pd.read_excel(\"datatest.xlsx\")\n",
        "test[test[\"label\"] == 3][\"label\"] = 2\n",
        "test[\"text\"] = test[\"text\"].apply(cleanIt)\n",
        "test[\"text\"] = test[\"text\"].apply(stopWord)\n",
        "test= tokenizerTest.texts_to_sequences(test[\"text\"])\n",
        "test = tf.keras.preprocessing.sequence.pad_sequences(test,maxlen=MAX_LENGTHS)\n",
        "pred = np.argmax(model.predict(test),axis=1)\n",
        "\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qsgKjgJhG1NO0kmUbg5LvGf0SNXckPoU\n",
            "To: /content/datatest.xlsx\n",
            "\r  0% 0.00/9.41k [00:00<?, ?B/s]\r100% 9.41k/9.41k [00:00<00:00, 9.73MB/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}